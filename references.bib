% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Huber1985-zq,
  title    = "Projection Pursuit",
  author   = "Huber, Peter J",
  abstract = "Projection pursuit is concerned with ``interesting'' projections
              of high dimensional data sets, with finding such projections by
              machine, and with using them for nonparametric fitting and other
              data-analytic purposes. This survey attempts to put the
              fascinating problems and ramifications of projection
              pursuit--which range from principal components, multidimensional
              scaling, factor analysis, nonparametric regression, density
              estimation and deconvolution of time series to computer
              tomography and problems in pure mathematics--into a coherent
              perspective",
  journal  = "Ann. Stat.",
  volume   =  13,
  number   =  2,
  pages    = "435--475",
  month    =  jun,
  year     =  1985,
  language = "EN"
}


@ARTICLE{Friedman1974-ck,
  title    = "A Projection Pursuit Algorithm for Exploratory Data Analysis",
  author   = "Friedman, J H and Tukey, J W",
  abstract = "An algorithm for the analysis of multivariate data is presented
              and is discussed in terms of specific examples. The algorithm
              seeks to find one-and two-dimensional linear projections of
              multivariate data that are relatively highly revealing.",
  journal  = "IEEE Trans. Comput.",
  volume   = "C-23",
  number   =  9,
  pages    = "881--890",
  month    =  sep,
  year     =  1974,
  keywords = "Clustering, dimensionality reduction, mappings, multidimensional
              scaling, multivariate data analysis, nonparametric pattern
              recognition, statistics.;Clustering, dimensionality reduction,
              mappings, multidimensional scaling, multivariate data analysis,
              nonparametric pattern recognition, statistics."
}

@ARTICLE{Posse1995-ih,
  title    = "Tools for {Two-Dimensional} Exploratory Projection Pursuit",
  author   = "Posse, Christian",
  journal  = "J. Comput. Graph. Stat.",
  volume   =  4,
  number   =  2,
  pages    = "83--100",
  year     =  1995,
  language = "en"
}


@ARTICLE{Loperfido2018-ga,
  title     = "Skewness-based projection pursuit: A computational approach",
  author    = "Loperfido, Nicola",
  abstract  = "Projection pursuit is a multivariate statistical technique aimed
               at finding interesting low-dimensional data projections by
               maximizing a measure of interestingness commonly known as
               projection index. Widespread use of projection pursuit has been
               hampered by the computational difficulties inherent to the
               maximization of the projection index. The problem is addressed
               within the framework of skewness-based projection pursuit,
               focused on data projections with highest third standardized
               cumulants. First, it is motivated the use of the right dominant
               singular vector of the third multivariate, standardized moment
               to start the maximization procedure. Second, it is proposed an
               iterative algorithm for skewness maximization which relies on
               the analytically tractable maximization of a third-order
               polynomial in two variables. Both visual inspection and formal
               testing based on simulated data clearly suggest that the
               asymptotic distribution of the maximal skewness achievable by a
               linear projection of normal data might be skew-normal. The
               potential of skewness-based projection pursuit for uncovering
               data structures is illustrated with Olympic decathlon data.",
  journal   = "Comput. Stat. Data Anal.",
  publisher = "Elsevier",
  volume    =  120,
  number    = "C",
  pages     = "42--57",
  year      =  2018,
  keywords  = "Higher-order power method; Projection pursuit; Singular value
               decomposition; Skewness; Tensor eigenvector;"
}


@ARTICLE{Loperfido2020-xj,
  title     = "Kurtosis-based projection pursuit for outlier detection in
               financial time series",
  author    = "Loperfido, Nicola",
  abstract  = "Outlier detection in financial time series is made difficult by
               serial dependence, volatility clustering and heavy tails.
               Projections achieving maximal kurtosis proved to be useful for
               outlier detection in multivariate datasets but their widespread
               application has been hampered by computational and inferential
               difficulties. This paper addresses both problems within the
               framework of univariate and multivariate financial time series.
               Computation of projections with maximal kurtoses in univariate
               financial time series is simplified to a eigenvalue problem.
               Projections with maximal kurtoses in multivariate financial time
               series best separate outliers from the bulk of the data, under a
               finite mixture model. The paper also addresses kurtosis
               optimization within the framework of portfolio selection.
               Practical relevance of these theoretical results is illustrated
               with univariate and multivariate time series from several
               financial markets. Empirical results also suggest that
               projections removing excess kurtosis could transform a
               univariate financial time series to a time series very similar
               to a Gaussian process, while the effect of outliers might be
               alleviated by projections achieving minimal kurtosis.",
  journal   = "The European Journal of Finance",
  publisher = "Routledge",
  volume    =  26,
  number    = "2-3",
  pages     = "142--164",
  month     =  feb,
  year      =  2020
}


@ARTICLE{Lee2005-gl,
  title    = "Projection Pursuit for Exploratory Supervised Classification",
  author   = "Lee, Eun-Kyung and Cook, Dianne and Klinke, Sigbert and Lumley,
              Thomas",
  journal  = "J. Comput. Graph. Stat.",
  volume   =  14,
  number   =  4,
  pages    = "831--846",
  year     =  2005,
  language = "en"
}


@article{Laa2020-zj,
  title={Using tours to visually investigate properties of new projection pursuit indexes with application to problems in physics},
  author={Laa, Ursula and Cook, Dianne},
  journal={Computational Statistics},
  volume={35},
  number={3},
  pages={1171--1205},
  year={2020},
  publisher={Springer}
}

@ARTICLE{Van_der_Maaten2008-qa,
  title    = "Visualizing Data using {t-SNE}",
  author   = "van der Maaten, Laurens and Hinton, Geoffrey",
  journal  = "J. Mach. Learn. Res.",
  volume   =  9,
  number   = "Nov",
  pages    = "2579--2605",
  year     =  2008,
  url      = "http://www.jmlr.org/papers/v9/vandermaaten08a.html",
  keywords = "wiley-review-paper;paper-tsne-liminal",
  issn     = "1532-4435, 1533-7928"
}

@INPROCEEDINGS{Buja1986-sw,
  title     = "Grand tour methods: an outline",
  booktitle = "Proceedings of the Seventeenth Symposium on the interface of
               computer sciences and statistics on Computer science and
               statistics",
  author    = "Buja, Andreas and Asimov, Daniel",
  publisher = "Elsevier North-Holland, Inc.",
  pages     = "63--67",
  month     =  jun,
  year      =  1986,
  url       = "https://dl.acm.org/doi/10.5555/26036.26046",
  address   = "USA",
  keywords  = "wiley-review-paper;high-dimensions",
  location  = "Lexington, Kentucky, USA",
  isbn      = "9780444700186"
}

@ARTICLE{Buja2008-yb,
  title     = "Data Visualization With Multidimensional Scaling",
  author    = "Buja, Andreas and Swayne, Deborah F and Littman, Michael L and
               Dean, Nathaniel and Hofmann, Heike and Chen, Lisha",
  abstract  = "We discuss methodology for multidimensional scaling (MDS) and
               its implementation in two software systems, GGvis and XGvis. MDS
               is a visualization technique for proximity data, that is, data
               in the form of N ? N dissimilarity matrices. MDS constructs maps
               (?configurations,? ?embeddings?) in IRk by interpreting the
               dissimilarities as distances. Two frequent sources of
               dissimilarities are high-dimensional data and graphs. When the
               dissimilarities are distances between high-dimensional objects,
               MDS acts as a (often nonlinear) dimension-reduction technique.
               When the dissimilarities are shortest-path distances in a graph,
               MDS acts as a graph layout technique. MDS has found recent
               attention in machine learning motivated by image databases
               (?Isomap?). MDS is also of interest in view of the popularity of
               ?kernelizing? approaches inspired by Support Vector Machines
               (SVMs; ?kernel PCA?).This article discusses the following
               general topics: (1) the stability and multiplicity of MDS
               solutions; (2) the analysis of structure within and between
               subsets of objects with missing value schemes in dissimilarity
               matrices; (3) gradient descent for optimizing general MDS loss
               functions (?Strain? and ?Stress?); (4) a unification of
               classical (Strain-based) and distance (Stress-based)
               MDS.Particular topics include the following: (1) blending of
               automatic optimization with interactive displacement of
               configuration points to assist in the search for global optima;
               (2) forming groups of objects with interactive brushing to
               create patterned missing values in MDS loss functions; (3)
               optimizing MDS loss functions for large numbers of objects
               relative to a small set of anchor points (?external unfolding?);
               and (4) a non-metric version of classical MDS.We show
               applications to the mapping of computer usage data, to the
               dimension reduction of marketing segmentation data, to the
               layout of mathematical graphs and social networks, and finally
               to the spatial reconstruction of molecules.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  17,
  number    =  2,
  pages     = "444--472",
  month     =  jun,
  year      =  2008,
  url       = "https://doi.org/10.1198/106186008X318440",
  keywords  = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  eprint    = "http://dx.doi.org/10.1198/106186008X318440",
  issn      = "1061-8600",
  doi       = "10.1198/106186008X318440"
}

@INPROCEEDINGS{Swayne2004-wx,
  title     = "Exploratory Visual Analysis of Graphs in {GGOBI}",
  booktitle = "{COMPSTAT} 2004 --- Proceedings in Computational Statistics",
  author    = "Swayne, Deborah F and Buja, Andreas",
  abstract  = "Graphs have long been of interest in telecommunications and
               social network analysis, and they are now receiving increasing
               attention from statisticians working in other areas,
               particularly in biostatistics. Most of the visualization
               software available for working with graphs has come from outside
               statistics and has not included the kind of interaction that
               statisticians have come to expect. At the same time, most of the
               exploratory visualization software available to statisticians
               has made no provision for the special structure of graphs.",
  publisher = "Physica-Verlag HD",
  pages     = "477--488",
  year      =  2004,
  url       = "http://dx.doi.org/10.1007/978-3-7908-2656-2_39",
  keywords  = "wiley-review-paper;interactive-graphics",
  doi       = "10.1007/978-3-7908-2656-2\_39"
}

@ARTICLE{Swayne2003-cc,
  title     = "{{GGobi}}: Evolving from {XGobi} into an extensible framework
               for interactive data visualization",
  author    = "Swayne, Deborah F and Lang, Duncan Temple and Buja, Andreas and
               Cook, Dianne",
  journal   = "Comput. Stat. Data Anal.",
  publisher = "Elsevier",
  volume    =  43,
  number    =  4,
  pages     = "423--444",
  month     =  aug,
  year      =  2003,
  url       = "https://research.monash.edu/en/publications/ggobi-evolving-from-xgobi-into-an-extensible-framework-for-intera",
  keywords  = "API; Interoperability; Plugins; R; Statistical graphics;
               XML;wiley-review-paper;interactive-graphics",
  language  = "en",
  issn      = "0167-9473",
  doi       = "10.1016/S0167-9473(02)00286-4"
}

@INPROCEEDINGS{Buja1986-la,
  title     = "A data viewer for multivariate data",
  booktitle = "Computing Science and Statistics: Proceedings of the 18th
               Symposium on the Interface",
  author    = "Buja, Andreas and Hurley, Catherine and McDonald, John",
  publisher = "American Statistical Association",
  pages     = "171--174",
  year      =  1986,
  address   = "Washington",
  keywords  = "wiley-review-paper;interactive-graphics",
  location  = "Washington"
}

@ARTICLE{Swayne1998-cf,
  title     = "{{XGobi}}: Interactive Dynamic Data Visualization in the {X}
               Window System",
  author    = "Swayne, Deborah F and Cook, Dianne and Buja, Andreas",
  abstract  = "Abstract XGobi is a data visualization system with
               state-of-the-art interactive and dynamic methods for the
               manipulation of views of data. It implements 2-D displays of
               projections of points and lines in high-dimensional spaces, as
               well as parallel coordinate displays and textual views thereof.
               Projection tools include dotplots of single variables, plots of
               pairs of variables, 3-D data rotations, various grand tours, and
               interactive projection pursuit. Views of the data can be
               reshaped. Points can be labeled and brushed with glyphs and
               colors. Lines can be edited and colored. Several XGobi processes
               can be run simultaneously and linked for labeling, brushing, and
               sharing of projections. Missing data are accommodated and their
               patterns can be examined; multiple imputations can be given to
               XGobi for rapid visual diagnostics. XGobi includes an extensive
               online help facility. XGobi can be integrated in other software
               systems, as has been done for the data analysis language S, the
               geographic information system (GIS) Arc View?, and the
               interactive multidimensional scaling program XGvis. XGobi is
               implemented in the X Window System? for portability as well as
               the ability to run across a network.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  7,
  number    =  1,
  pages     = "113--130",
  month     =  mar,
  year      =  1998,
  url       = "https://www.tandfonline.com/doi/abs/10.1080/10618600.1998.10474764",
  keywords  = "wiley-review-paper;interactive-graphics",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.1998.10474764"
}

@ARTICLE{Cook1995-ae,
  title     = "Grand Tour and Projection Pursuit",
  author    = "Cook, Dianne and Buja, Andreas and Cabrera, Javier and Hurley,
               Catherine",
  abstract  = "Abstract The grand tour and projection pursuit are two methods
               for exploring multivariate data. We show how to combine them
               into a dynamic graphical tool for exploratory data analysis,
               called a projection pursuit guided tour. This tool assists in
               clustering data when clusters are oddly shaped and in finding
               general low-dimensional structure in high-dimensional, and in
               particular, sparse data. An example shows that the method, which
               is projection-based, can be quite powerful in situations that
               may cause grief for methods based on kernel smoothing. The
               projection pursuit guided tour is also useful for comparing and
               developing projection pursuit indexes and illustrating some
               types of asymptotic results.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  4,
  number    =  3,
  pages     = "155--172",
  month     =  sep,
  year      =  1995,
  url       = "https://www.tandfonline.com/doi/abs/10.1080/10618600.1995.10474674",
  keywords  = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.1995.10474674"
}


@TECHREPORT{Carr1984-xw,
  title       = "Graphical interaction tools for multiple 2- and 3-dimensional
                 scatterplots",
  author      = "Carr, D B and Nicholson, W L",
  number      = "PNL-SA-12095; CONF-8405194-2",
  institution = "Pacific Northwest Lab., Richland, WA (USA)",
  month       =  feb,
  year        =  1984,
  url         = "https://www.osti.gov/biblio/6872143",
  language    = "en"
}


@INCOLLECTION{Chambers1983-dh,
  title     = "Plotting Multivariate Data",
  booktitle = "Graphical Methods for Data Analysis",
  author    = "Chambers, John M and Cleveland, William S and Kleiner, Beat and
               Tukey, Paul A",
  publisher = "Duxbury Press",
  pages     = "129--190",
  year      =  1983,
  url       = "http://dx.doi.org/10.1201/9781351072304-5",
  address   = "Boston",
  doi       = "10.1201/9781351072304-5"
}




@ARTICLE{Becker1987-dw,
  title     = "Brushing Scatterplots",
  author    = "Becker, Richard A and Cleveland, William S",
  abstract  = "[A dynamic graphical method is one in which a data analyst
               interacts in real time with a data display on a computer
               graphics terminal. Using a screen input device such as a mouse,
               the analyst can specify, in a visual way, points or regions on
               the display and cause aspects of the display to change nearly
               instantaneously. Brushing is a collection of dynamic methods for
               viewing multidimensional data. It is very effective when used on
               a scatterplot matrix, a rectangular array of all pairwise
               scatterplots of the variables. Four brushing
               operations-highlight, shadow highlight, delete, and label-are
               carried out by moving a mouse-controlled rectangle, called the
               brush, over one of the scatterplots. The effect of an operation
               appears simultaneously on all scatterplots. Three paint
               modes-transient, lasting, and undo-and the ability to change the
               shape of the brush allow the analyst to specify collections of
               points on which the operations are carried out. Brushing can be
               used in various ways or on certain types of data; these usages
               are called brush techniques and include the following:
               single-point and cluster linking, conditioning on a single
               variable, conditioning on two variables, subsetting with
               categorical variables, and stationarity probing of a time
               series.]",
  journal   = "Technometrics",
  publisher = "[Taylor \& Francis, Ltd., American Statistical Association,
               American Society for Quality]",
  volume    =  29,
  number    =  2,
  pages     = "127--142",
  year      =  1987,
  url       = "http://www.jstor.org/stable/1269768",
  keywords  = "wiley-review-paper;interactive-graphics;tukey-esque",
  issn      = "0040-1706",
  doi       = "10.2307/1269768"
}

@PHDTHESIS{McDonald1982-ht,
  title    = "Interactive graphics for data analysis",
  author   = "McDonald, J A",
  year     =  1982,
  url      = "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.6673&rep=rep1&type=pdf",
  school   = "Stanford University",
  keywords = "wiley-review-paper;interactive-graphics"
}

@UNPUBLISHED{Moon2019-ne,
  title    = "Visualizing Structure and Transitions for Biological Data
              Exploration",
  author   = "Moon, Kevin R and van Dijk, David and Wang, Zheng and Gigante,
              Scott and Burkhardt, Daniel B and Chen, William S and Yim,
              Kristina and van den Elzen, Antonia and Hirn, Matthew J and
              Coifman, Ronald R and Ivanova, Natalia B and Wolf, Guy and
              Krishnaswamy, Smita",
  abstract = "Abstract With the advent of high-throughput technologies
              measuring high-dimensional biological data, there is a pressing
              need for visualization tools that reveal the structure and
              emergent patterns of data in an intuitive form. We present PHATE,
              a visualization method that captures both local and global
              nonlinear structure in data by an information-geometric distance
              between datapoints. We perform extensive comparison between PHATE
              and other tools on a variety of artificial and biological
              datasets, and find that it consistently preserves a range of
              patterns in data including continual progressions, branches, and
              clusters. We define a manifold preservation metric DEMaP to show
              that PHATE produces quantitatively better denoised embeddings
              than existing visualization methods. We show that PHATE is able
              to gain unique insight from a newly generated scRNA-seq dataset
              of human germ layer differentiation. Here, PHATE reveals a
              dynamic picture of the main developmental branches in
              unparalleled detail, including the identification of three novel
              subpopulations. Finally, we show that PHATE is applicable to a
              wide variety of datatypes including mass cytometry, single-cell
              RNA-sequencing, Hi-C, and gut microbiome data, where it can
              generate interpretable insights into the underlying systems.",
  month    =  apr,
  year     =  2019,
  url      = "https://www.biorxiv.org/content/10.1101/120378v4",
  keywords = "wiley-review-paper;paper-tsne-liminal",
  language = "en"
}

@ARTICLE{Satyanarayan2016-jt,
  title    = "Reactive Vega: A Streaming Dataflow Architecture for Declarative
              Interactive Visualization",
  author   = "Satyanarayan, A and Russell, R and Hoffswell, J and Heer, J",
  abstract = "We present Reactive Vega, a system architecture that provides the
              first robust and comprehensive treatment of declarative visual
              and interaction design for data visualization. Starting from a
              single declarative specification, Reactive Vega constructs a
              dataflow graph in which input data, scene graph elements, and
              interaction events are all treated as first-class streaming data
              sources. To support expressive interactive visualizations that
              may involve time-varying scalar, relational, or hierarchical
              data, Reactive Vega's dataflow graph can dynamically re-write
              itself at runtime by extending or pruning branches in a
              data-driven fashion. We discuss both compile- and run-time
              optimizations applied within Reactive Vega, and share the results
              of benchmark studies that indicate superior interactive
              performance to both D3 and the original, non-reactive Vega
              system.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  22,
  number   =  1,
  pages    = "659--668",
  month    =  jan,
  year     =  2016,
  url      = "http://dx.doi.org/10.1109/TVCG.2015.2467091",
  keywords = "data flow graphs;data visualisation;formal
              specification;optimisation;Reactive Vega;streaming dataflow
              architecture;declarative interactive visualization;system
              architecture;declarative visual design;interaction design;data
              visualization;single declarative specification;dataflow
              graph;scene graph elements;interaction events;first-class
              streaming data sources;expressive interactive
              visualizations;time-varying scalar;relational data;hierarchical
              data;compile-time optimization;run-time optimization;interactive
              performance;Data visualization;Visualization;Data
              models;Encoding;Indexes;Runtime;Computer architecture;Information
              visualization;systems;toolkits;declarative
              specification;optimization;interaction;streaming data;Information
              visualization;systems;toolkits;declarative
              specification;optimization;interaction;streaming
              data;wiley-review-paper;paper-tsne-liminal",
  issn     = "1077-2626, 2160-9306",
  doi      = "10.1109/TVCG.2015.2467091"
}

@ARTICLE{Bostock2011-hq,
  title    = "D3: {Data-Driven} Documents",
  author   = "Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey",
  abstract = "Data-Driven Documents (D3) is a novel representation-transparent
              approach to visualization for the web. Rather than hide the
              underlying scenegraph within a toolkit-specific abstraction, D3
              enables direct inspection and manipulation of a native
              representation: the standard document object model (DOM). With
              D3, designers selectively bind input data to arbitrary document
              elements, applying dynamic transforms to both generate and modify
              content. We show how representational transparency improves
              expressiveness and better integrates with developer tools than
              prior approaches, while offering comparable notational efficiency
              and retaining powerful declarative components. Immediate
              evaluation of operators further simplifies debugging and allows
              iterative development. Additionally, we demonstrate how D3
              transforms naturally enable animation and interaction with
              dramatic performance improvements over intermediate
              representations.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  17,
  number   =  12,
  pages    = "2301--2309",
  month    =  dec,
  year     =  2011,
  url      = "http://dx.doi.org/10.1109/TVCG.2011.185",
  keywords = "wiley-review-paper;paper-tsne-liminal",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "22034350",
  doi      = "10.1109/TVCG.2011.185"
}

@INCOLLECTION{Cook2006-rb,
  title     = "Rotating Plots",
  booktitle = "Graphics of Large Datasets: Visualizing a Million",
  author    = "Cook, Dianne and Miller, Leslie",
  editor    = "Unwin, Antony and Theus, Martin and Hofmann, Heike",
  publisher = "Springer New York",
  pages     = "125--141",
  year      =  2006,
  url       = "https://doi.org/10.1007/0-387-37977-0_6",
  address   = "New York, NY",
  keywords  = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  isbn      = "9780387379777",
  doi       = "10.1007/0-387-37977-0\_6"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Van_der_Maaten2014-um,
  title     = "Accelerating {t-SNE} using tree-based algorithms",
  author    = "van der Maaten, Laurens",
  abstract  = "The paper investigates the acceleration of t-SNE---an embedding
               technique that is commonly used for the visualization of
               high-dimensional data in scatter plots---using two treebased
               algorithms. In particular, the paper develops variants of the
               Barnes-Hut algorithm and of the dual-tree algorithm that
               approximate the gradient used for learning t-SNE embeddings in O
               (N log N). Our experiments show that the resulting algorithms
               substantially accelerate t-SNE, and that they make it possible
               to learn embeddings of data sets with …",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  year      =  2014,
  url       = "http://www.jmlr.org/papers/volume15/vandermaaten14a/vandermaaten14a.pdf",
  keywords  = "wiley-review-paper;paper-tsne-liminal",
  issn      = "1532-4435"
}

@UNPUBLISHED{McInnes2018-hb,
  title    = "{{UMAP}}: Uniform Manifold Approximation and Projection for
              Dimension Reduction",
  author   = "McInnes, Leland and Healy, John and Melville, James",
  abstract = "UMAP (Uniform Manifold Approximation and Projection) is a novel
              manifold learning technique for dimension reduction. UMAP is
              constructed from a theoretical framework based in Riemannian
              geometry and algebraic topology. The result is a practical
              scalable algorithm that applies to real world data. The UMAP
              algorithm is competitive with t-SNE for visualization quality,
              and arguably preserves more of the global structure with superior
              run time performance. Furthermore, UMAP has no computational
              restrictions on embedding dimension, making it viable as a
              general purpose dimension reduction technique for machine
              learning.",
  month    =  feb,
  year     =  2018,
  url      = "http://arxiv.org/abs/1802.03426",
  keywords = "wiley-review-paper;paper-tsne-liminal"
}

@ARTICLE{Furnas1994-dz,
  title     = "Prosection Views: Dimensional Inference through Sections and
               Projections",
  author    = "Furnas, George W and Buja, Andreas",
  abstract  = "Abstract We present some basic properties of two general
               graphical techniques for constructing views of high-dimensional
               objects, projection and section. Projections can easily display
               aspects of structure that are only of low dimension, and
               sections?that is, intersections of subspaces with a
               high-dimensional object?can easily display structure of only low
               codimension (and hence often high dimension). However,
               compositions of sections and projections, here called
               prosections, can display aspects of structure of any
               intermediate dimension. These statements are relevant for data
               analysis: projections of data can be easily generated with x-y
               scatterplots, three-dimensional (3-D) data rotations, and grand
               tours; sections can be approximated in existing systems by
               scatterplot brushing and painting. Thus this article is in part
               an investigation into the principles underlying these
               techniques.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.,
               Institute of Mathematical Statistics, Interface Foundation of
               America]",
  volume    =  3,
  number    =  4,
  pages     = "323--353",
  series    = "Ph.D. thesis",
  month     =  dec,
  year      =  1994,
  url       = "http://www.tandfonline.com/doi/abs/10.1080/10618600.1994.10474649",
  keywords  = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  issn      = "1061-8600, 1537-2715",
  doi       = "10.1080/10618600.1994.10474649"
}

@INPROCEEDINGS{Dang2014-ck,
  title     = "{{ScagExplorer}}: Exploring Scatterplots by Their Scagnostics",
  booktitle = "2014 {IEEE} Pacific Visualization Symposium",
  author    = "Dang, T N and Wilkinson, L",
  abstract  = "A scatter plot displays a relation between a pair of variables.
               Given a set of v variables, there are v(v- 1)/2 pairs of
               variables, and thus the same number of possible pair wise
               scatter plots. Therefore for even small sets of variables, the
               number of scatter plots can be large. Scatter plot matrices
               (SPLOMs) can easily run out of pixels when presenting
               high-dimensional data. We introduce a theoretical method and a
               testbed for assessing whether our method can be used to guide
               interactive exploration of high-dimensional data. The method is
               based on nine characterizations of the 2D distributions of
               orthogonal pair wise projections on a set of points in
               multidimensional Euclidean space. Working directly with these
               characterizations, we can locate anomalies for further analysis
               or search for similar distributions in a large SPLOM with more
               than a hundred dimensions. Our testbed, ScagExplorer, is
               developed in order to evaluate the feasibility of handling huge
               collections of scatter plots.",
  pages     = "73--80",
  month     =  mar,
  year      =  2014,
  url       = "http://dx.doi.org/10.1109/PacificVis.2014.42",
  keywords  = "computer graphics;data handling;graph theory;interactive
               systems;2D distributions;ScagExplorer;high-dimensional
               data;interactive exploration;large SPLOM;multidimensional
               Euclidean space;orthogonal pairwise projections;pairwise
               scatterplots;scatterplot matrices;theoretical
               method;variables;Clustering algorithms;Correlation;Data
               visualization;Educational institutions;Layout;Silicon;Time
               series analysis;Design MethodologyPattern
               analysis;High-Dimensional Visual Analytics;Leader
               algorithm;Scagnostics;Scatterplot matrix;forced-directed
               layout;wiley-review-paper;paper-tsne-liminal;high-dimensions;tukey-esque",
  issn      = "2165-8773",
  doi       = "10.1109/PacificVis.2014.42"
}

@INPROCEEDINGS{Anand2012-gc,
  title     = "Visual Pattern Discovery Using Random Projections",
  booktitle = "Proceedings of the 2012 {IEEE} Conference on Visual Analytics
               Science and Technology ({{VAST}})",
  author    = "Anand, Anushka and Dang, Tuan Nhon and Wilkinson, Leland",
  publisher = "IEEE Computer Society",
  pages     = "43--52",
  series    = "VAST '12",
  year      =  2012,
  url       = "http://dx.doi.org/10.1109/VAST.2012.6400490",
  address   = "Washington, DC, USA",
  keywords  = "Vectors,Data visualization,Data mining,Manifolds,Indexes,Visual
               analytics,High-dimensional Data,Random
               Projections;wiley-review-paper;paper-tsne-liminal;high-dimensions;tukey-esque",
  isbn      = "9781467347525",
  doi       = "10.1109/VAST.2012.6400490"
}

@ARTICLE{Chen2009-vn,
  title     = "Local Multidimensional Scaling for Nonlinear Dimension
               Reduction, Graph Drawing, and Proximity Analysis",
  author    = "Chen, Lisha and Buja, Andreas",
  abstract  = "In the past decade there has been a resurgence of interest in
               nonlinear dimension reduction. Among new proposals are ?Local
               Linear Embedding,? ?Isomap,? and Kernel Principal Components
               Analysis which all construct global low-dimensional embeddings
               from local affine or metric information. We introduce a
               competing method called ?Local Multidimensional Scaling? (LMDS).
               Like LLE, Isomap, and KPCA, LMDS constructs its global embedding
               from local information, but it uses instead a combination of MDS
               and ?force-directed? graph drawing. We apply the force paradigm
               to create localized versions of MDS stress functions with a
               tuning parameter to adjust the strength of nonlocal repulsive
               forces. We solve the problem of tuning parameter selection with
               a meta-criterion that measures how well the sets of K-nearest
               neighbors agree between the data and the embedding. Tuned LMDS
               seems to be able to outperform MDS, PCA, LLE, Isomap, and KPCA,
               as illustrated with two well-known image datasets. The
               meta-criterion can also be used in a pointwise version as a
               diagnostic tool for measuring the local adequacy of embeddings
               and thereby detect local problems in dimension reductions.",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "amstat.tandfonline.com",
  volume    =  104,
  number    =  485,
  pages     = "209--219",
  month     =  mar,
  year      =  2009,
  url       = "https://doi.org/10.1198/jasa.2009.0111",
  keywords  = "wiley-review-paper;paper-tsne-liminal;interactive-graphics;high-dimensions",
  issn      = "0162-1459",
  doi       = "10.1198/jasa.2009.0111"
}

@ARTICLE{Satyanarayan2017-ck,
  title    = "{{Vega-Lite}}: A Grammar of Interactive Graphics",
  author   = "Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat,
              Kanit and Heer, Jeffrey",
  abstract = "We present Vega-Lite, a high-level grammar that enables rapid
              specification of interactive data visualizations. Vega-Lite
              combines a traditional grammar of graphics, providing visual
              encoding rules and a composition algebra for layered and
              multi-view displays, with a novel grammar of interaction. Users
              specify interactive semantics by composing selections. In
              Vega-Lite, a selection is an abstraction that defines input event
              processing, points of interest, and a predicate function for
              inclusion testing. Selections parameterize visual encodings by
              serving as input data, defining scale extents, or by driving
              conditional logic. The Vega-Lite compiler automatically
              synthesizes requisite data flow and event handling logic, which
              users can override for further customization. In contrast to
              existing reactive specifications, Vega-Lite selections decompose
              an interaction design into concise, enumerable semantic units. We
              evaluate Vega-Lite through a range of examples, demonstrating
              succinct specification of both customized interaction methods and
              common techniques such as panning, zooming, and linked selection.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  23,
  number   =  1,
  pages    = "341--350",
  month    =  jan,
  year     =  2017,
  url      = "http://dx.doi.org/10.1109/TVCG.2016.2599030",
  keywords = "wiley-review-paper;paper-tsne-liminal;constraint-programming",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "27875150",
  doi      = "10.1109/TVCG.2016.2599030"
}

@INCOLLECTION{Cook2008-nl,
  title     = "Grand Tours, Projection Pursuit Guided Tours, and Manual
               Controls",
  booktitle = "Handbook of Data Visualization",
  author    = "Cook, Dianne and Buja, Andreas and Lee, Eun-Kyung and Wickham,
               Hadley",
  editor    = "Chen, Chun-Houh and H{\"a}rdle, Wolfgang and Unwin, Antony",
  abstract  = "How do we find structure in multidimensional data when computer
               screens are only two-dimensional? One approach is to project the
               data onto one or two dimensions. Projections are used in
               classical statistical methods like principal component analysis
               (PCA) and linear discriminant analysis. PCA (e.g., Johnson and
               Wichern 2002) chooses a projection to maximize the variance.
               Fisher's linear discriminant (e.g., Johnson and Wichern 2002)
               chooses a projection that maximizes the relative separation
               between group means. Projection pursuit (PP) (e.g., Huber 1985)
               generalizes these ideas into a common strategy, where an
               arbitrary function on projections is optimized. The scatterplot
               matrix (e.g., Becker and Cleveland 1987) also can be considered
               to be a projection method. It shows projections of the data onto
               all pairs of coordinate axes, the 2-D marginal projections of
               the data. These projection methods choose a few select
               projections out of infinitely many.",
  publisher = "Springer Berlin Heidelberg",
  pages     = "295--314",
  series    = "Springer Handbooks Comp.Statistics",
  year      =  2008,
  url       = "https://doi.org/10.1007/978-3-540-33037-0_13",
  address   = "Berlin, Heidelberg",
  keywords  = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  language  = "en",
  isbn      = "9783540330370, 9783540330370",
  doi       = "10.1007/978-3-540-33037-0\_13"
}

@ARTICLE{Diaconis2008-yh,
  title         = "Horseshoes in multidimensional scaling and local kernel
                   methods",
  author        = "Diaconis, Persi and Goel, Sharad and Holmes, Susan",
  abstract      = "Classical multidimensional scaling (MDS) is a method for
                   visualizing high-dimensional point clouds by mapping to
                   low-dimensional Euclidean space. This mapping is defined in
                   terms of eigenfunctions of a matrix of interpoint
                   dissimilarities. In this paper we analyze in detail
                   multidimensional scaling applied to a specific dataset: the
                   2005 United States House of Representatives roll call votes.
                   Certain MDS and kernel projections output ``horseshoes''
                   that are characteristic of dimensionality reduction
                   techniques. We show that, in general, a latent ordering of
                   the data gives rise to these patterns when one only has
                   local information. That is, when only the interpoint
                   distances for nearby points are known accurately. Our
                   results provide a rigorous set of results and insight into
                   manifold learning in the special case where the manifold is
                   a curve.",
  month         =  nov,
  year          =  2008,
  url           = "http://arxiv.org/abs/0811.1477",
  keywords      = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  archivePrefix = "arXiv",
  eprint        = "0811.1477",
  primaryClass  = "stat.AP",
  arxivid       = "0811.1477",
  doi           = "10.1214/08-AOAS165"
}

@INCOLLECTION{Buja1988-fh,
  title     = "Elements of a viewing pipeline for data analysis",
  booktitle = "Dynamic Graphics for Statistics",
  author    = "Buja, Andreas and Asimov, Daniel and Hurley, Catherine and
               McDonald, John A",
  editor    = "Cleveland, William S and McGill, Marylyn E",
  publisher = "Wadsworth \& Brooks/Cole",
  series    = "Statistics/Probability",
  year      =  1988,
  url       = "https://books.google.com.au/books?hl=en&lr=&id=pZTIv3uq1KsC&oi=fnd&pg=PA277&dq=elements+of+a+data+pipeline&ots=4cuJM6NpDN&sig=ugfwt2lDvTN7-hGlrCdQKCtsx5w",
  keywords  = "wiley-review-paper;paper-tsne-liminal;interactive-graphics"
}

@BOOK{Wickham2016-je,
  title     = "ggplot2: Elegant Graphics for Data Analysis",
  author    = "Wickham, Hadley",
  abstract  = "This new edition to the classic book by ggplot2 creator Hadley
               Wickham highlights compatibility with knitr and RStudio. ggplot2
               is a data visualization package for R that helps users create
               data graphics, including those that are multi-layered, with
               ease. With ggplot2, it's easy to: produce handsome,
               publication-quality plots with automatic legends created from
               the plot specificationsuperimpose multiple layers (points,
               lines, maps, tiles, box plots) from different data sources with
               automatically adjusted common scalesadd customizable smoothers
               that use powerful modeling capabilities of R, such as loess,
               linear models, generalized additive models, and robust
               regressionsave any ggplot2 plot (or part thereof) for later
               modification or reusecreate custom themes that capture in-house
               or journal style requirements and that can easily be applied to
               multiple plotsapproach a graph from a visual perspective,
               thinking about how each component of the data is represented on
               the final plot This book will be useful to everyone who has
               struggled with displaying data in an informative and attractive
               way. Some basic knowledge of R is necessary (e.g., importing
               data into R). ggplot2 is a mini-language specifically tailored
               for producing graphics, and you'll learn everything you need in
               the book. After reading this book you'll be able to produce
               graphics customized precisely for your problems, and you'll find
               it easy to get graphics out of your head and on to the screen or
               page.",
  publisher = "Springer International Publishing",
  series    = "Use R!",
  month     =  jun,
  year      =  2016,
  url       = "https://play.google.com/store/books/details?id=RTMFswEACAAJ",
  keywords  = "wiley-review-paper;books-computing;books-viz;paper-tsne-liminal;constraint-programming",
  language  = "en",
  isbn      = "9783319242750, 9783319242774",
  doi       = "10.1007/978-3-319-24277-4"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@BOOK{Cook2007-be,
  title     = "Interactive and Dynamic Graphics for Data Analysis: With {R} and
               {GGobi}",
  author    = "Cook, Dianne and Swayne, Deborah F and Buja, A",
  abstract  = "This book is about using interactive and dynamic plots on a
               computer screen as part of data exploration and modeling, both
               alone and as a partner with static graphics and non-graphical
               computational methods. The area of int- active and dynamic data
               visualization emerged within statistics as part of research on
               exploratory data analysis in the late 1960s, and it remains an
               active subject of research today, as its use in practice
               continues to grow. It now makes substantial contributions within
               computer science as well, as part of the growing ?elds of
               information visualization and data mining, especially visual
               data mining. The material in this book includes: • An
               introduction to data visualization, explaining how it di?ers
               from other types of visualization. •
               Adescriptionofourtoolboxofinteractiveanddynamicgraphicalmethods.
               • An approach for exploring missing values in data. • An
               explanation of the use of these tools in cluster analysis and
               supervised classi?cation. • An overview of additional material
               available on the web. • A description of the data used in the
               analyses and exercises. The book's examples use the software R
               and GGobi. R (Ihaka \& Gent- man 1996, RDevelopment
               CoreTeam2006) isafreesoftware environment for statistical
               computing and graphics; it is most often used from the command
               line, provides a wide variety of statistical methods, and
               includes high--quality
               staticgraphics.RaroseintheStatisticsDepartmentoftheUniversityofAu-
               land and is now developed and maintained by a global
               collaborative e?ort.",
  publisher = "Springer Science \& Business Media",
  series    = "Use R!",
  month     =  dec,
  year      =  2007,
  url       = "https://play.google.com/store/books/details?id=34DL7lR_4CoC",
  keywords  = "wiley-review-paper;books-computing;books-viz;paper-tsne-liminal;interactive-graphics",
  language  = "en",
  isbn      = "9780387717616, 9780387717623",
  doi       = "10.1007/978-0-387-71762-3"
}

@ARTICLE{Buja1996-yl,
  title     = "Interactive {High-Dimensional} Data Visualization",
  author    = "Buja, Andreas and Cook, Dianne and Swayne, Deborah F",
  abstract  = "Abstract We propose a rudimentary taxonomy of interactive data
               visualization based on a triad of data analytic tasks: finding
               Gestalt, posing queries, and making comparisons. These tasks are
               supported by three classes of interactive view manipulations:
               focusing, linking, and arranging views. This discussion extends
               earlier work on the principles of focusing and linking and sets
               them on a firmer base. Next, we give a high-level introduction
               to a particular system for multivariate data
               visualization?XGobi. This introduction is not comprehensive but
               emphasizes XGobi tools that are examples of focusing, linking,
               and arranging views; namely, high-dimensional projections,
               linked scatterplot brushing, and matrices of conditional plots.
               Finally, in a series of case studies in data visualization, we
               show the powers and limitations of particular focusing, linking,
               and arranging tools. The discussion is dominated by
               high-dimensional projections that form an extremely
               well-developed part of XGobi. Of particular interest are the
               illustration of asymptotic normality of high-dimensional
               projections (a theorem of Diaconis and Freedman), the use of
               high-dimensional cubes for visualizing factorial experiments,
               and a method for interactively generating matrices of
               conditional plots with high-dimensional projections. Although
               there is a unifying theme to this article, each section?in
               particular the case studies?can be read separately.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.,
               Institute of Mathematical Statistics, Interface Foundation of
               America]",
  volume    =  5,
  number    =  1,
  pages     = "78--99",
  month     =  mar,
  year      =  1996,
  url       = "https://www.tandfonline.com/doi/abs/10.1080/10618600.1996.10474696",
  keywords  = "wiley-review-paper;paper-tsne-liminal;interactive-graphics",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.1996.10474696"
}

@ARTICLE{Unwin2018-wi,
  title     = "Ensemble Graphics",
  author    = "Unwin, Antony and Valero-Mora, Pedro",
  abstract  = "ABSTRACTOne graphic can convey a lot of information and several
               graphics linked together in a coherent ensemble can convey even
               more. This article describes the principles underlying ensemble
               graphics, their key dimensions, and where they are of most use.
               Ensemble graphics must have strong common themes and carefully
               constructed layouts. Appropriate interactive tools are
               important. Ensembles can be used flexibly for EDA or in a more
               structured fashion for supporting modeling and for
               presentations.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  27,
  number    =  1,
  pages     = "157--165",
  month     =  jan,
  year      =  2018,
  url       = "https://doi.org/10.1080/10618600.2017.1383264",
  keywords  = "wiley-review-paper;paper-tsne-liminal",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.2017.1383264"
}

@ARTICLE{Wickham2015-do,
  title     = "Visualizing statistical models: Removing the blindfold",
  author    = "Wickham, Hadley and Cook, Dianne and Hofmann, Heike",
  abstract  = "Visualization can help in model building, diagnosis, and in
               developing an understanding about how a model summarizes data.
               This paper proposes three strategies for visualizing statistical
               models: (i) display the model in the data space, (ii) look at
               all members of a collection, and (iii) explore the process of
               model fitting, not just the end result. Each strategy is
               accompanied by examples, including manova, classification
               algorithms, hierarchical clustering, ensembles of linear models,
               projection pursuit, self-organizing maps, and neural networks.",
  journal   = "Statistical Analysis and Data Mining: The ASA Data Science
               Journal",
  publisher = "Wiley Subscription Services, Inc., A Wiley Company",
  volume    =  8,
  number    =  4,
  pages     = "203--225",
  month     =  aug,
  year      =  2015,
  url       = "http://dx.doi.org/10.1002/sam.11271",
  keywords  = "model visualization; exploratory data analysis; data mining;
               classification; high-dimensional
               data;wiley-review-paper;paper-tsne-liminal;high-dimensions",
  issn      = "1932-1872",
  doi       = "10.1002/sam.11271"
}

@UNPUBLISHED{Tang2016-lr,
  title    = "Visualizing Large-scale and High-dimensional Data",
  author   = "Tang, Jian and Liu, Jingzhou and Zhang, Ming and Mei, Qiaozhu",
  abstract = "We study the problem of visualizing large-scale and
              high-dimensional data in a low-dimensional (typically 2D or 3D)
              space. Much success has been reported recently by techniques that
              first compute a similarity structure of the data points and then
              project them into a low-dimensional space with the structure
              preserved. These two steps suffer from considerable computational
              costs, preventing the state-of-the-art methods such as the t-SNE
              from scaling to large-scale and high-dimensional data (e.g.,
              millions of data points and hundreds of dimensions). We propose
              the LargeVis, a technique that first constructs an accurately
              approximated K-nearest neighbor graph from the data and then
              layouts the graph in the low-dimensional space. Comparing to
              t-SNE, LargeVis significantly reduces the computational cost of
              the graph construction step and employs a principled
              probabilistic model for the visualization step, the objective of
              which can be effectively optimized through asynchronous
              stochastic gradient descent with a linear time complexity. The
              whole procedure thus easily scales to millions of
              high-dimensional data points. Experimental results on real-world
              data sets demonstrate that the LargeVis outperforms the
              state-of-the-art methods in both efficiency and effectiveness.
              The hyper-parameters of LargeVis are also much more stable over
              different data sets.",
  month    =  feb,
  year     =  2016,
  url      = "http://arxiv.org/abs/1602.00370",
  keywords = "wiley-review-paper;paper-tsne-liminal"
}

@ARTICLE{Li2020-kg,
  title    = "Visualizing Neural Networks with the Grand Tour",
  author   = "Li, Mingwei and Zhao, Zhenge and Scheidegger, Carlos",
  journal  = "Distill",
  volume   =  5,
  number   =  3,
  month    =  mar,
  year     =  2020,
  url      = "https://distill.pub/2020/grand-tour",
  keywords = "wiley-review-paper;autoencoders",
  issn     = "2476-0757",
  doi      = "10.23915/distill.00025"
}

@ARTICLE{Coifman2005-nh,
  title    = "Geometric diffusions as a tool for harmonic analysis and
              structure definition of data: diffusion maps",
  author   = "Coifman, R R and Lafon, S and Lee, A B and Maggioni, M and
              Nadler, B and Warner, F and Zucker, S W",
  abstract = "We provide a framework for structural multiscale geometric
              organization of graphs and subsets of R(n). We use diffusion
              semigroups to generate multiscale geometries in order to organize
              and represent complex structures. We show that appropriately
              selected eigenfunctions or scaling functions of Markov matrices,
              which describe local transitions, lead to macroscopic
              descriptions at different scales. The process of iterating or
              diffusing the Markov matrix is seen as a generalization of some
              aspects of the Newtonian paradigm, in which local infinitesimal
              transitions of a system lead to global macroscopic descriptions
              by integration. We provide a unified view of ideas from data
              analysis, machine learning, and numerical analysis.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  102,
  number   =  21,
  pages    = "7426--7431",
  month    =  may,
  year     =  2005,
  url      = "http://dx.doi.org/10.1073/pnas.0500334102",
  keywords = "wiley-review-paper;paper-tsne-liminal",
  language = "en",
  issn     = "0027-8424",
  pmid     = "15899970",
  doi      = "10.1073/pnas.0500334102",
  pmc      = "PMC1140422"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Silva2003-us,
  title     = "Global versus local methods in nonlinear dimensionality
               reduction",
  author    = "Silva, V D and Tenenbaum, J B",
  abstract  = "Recently proposed algorithms for nonlinear dimensionality
               reduction fall broadly into two categories which have different
               advantages and disadvantages: global (Isomap [1]), and local
               (Locally Linear Embedding [2], Laplacian Eigenmaps [3]). We
               present two variants of …",
  journal   = "Adv. Neural Inf. Process. Syst.",
  publisher = "papers.nips.cc",
  year      =  2003,
  url       = "http://papers.nips.cc/paper/2141-global-versus-local-methods-in-nonlinear-dimensionality-reduction.pdf",
  keywords  = "wiley-review-paper;paper-tsne-liminal",
  issn      = "1049-5258"
}

@ARTICLE{Torgerson1952-zt,
  title     = "Multidimensional scaling: I. Theory and method",
  author    = "Torgerson, Warren S",
  abstract  = "Multidimensional scaling can be considered as involving three
               basic steps. In the first step, a scale of comparative distances
               between all pairs of stimuli is obtained. This scale is
               analogous to the scale of stimuli obtained in the traditional
               paired comparisons methods. In this scale, however, instead of
               locating each stimulus-object on a given continuum, the
               distances between each pair of stimuli are located on a distance
               continuum. As in paired comparisons, the procedures for
               obtaining a scale of comparative distances leave the true zero
               point undetermined. Hence, a comparative distance is not a
               distance in the usual sense of the term, but is a distance minus
               an unknown constant. The second step involves estimating this
               unknown constant. When the unknown constant is obtained, the
               comparative distances can be converted into absolute distances.
               In the third step, the dimensionality of the psychological space
               necessary to account for these absolute distances is determined,
               and the projections of stimuli on axes of this space are
               obtained. A set of analytical procedures was developed for each
               of the three steps given above, including a least-squares
               solution for obtaining comparative distances by the complete
               method of triads, two practical methods for estimating the
               additive constant, and an extension of Young and Householder's
               Euclidean model to include procedures for obtaining the
               projections of stimuli on axes from fallible absolute distances.",
  journal   = "Psychometrika",
  publisher = "Springer-Verlag",
  volume    =  17,
  number    =  4,
  pages     = "401--419",
  month     =  dec,
  year      =  1952,
  url       = "https://link.springer.com/article/10.1007/BF02288916",
  keywords  = "wiley-review-paper;high-dimensions",
  language  = "en",
  issn      = "0033-3123, 1860-0980",
  doi       = "10.1007/BF02288916"
}

@ARTICLE{Kruskal1964-do,
  title     = "Multidimensional scaling by optimizing goodness of fit to a
               nonmetric hypothesis",
  author    = "Kruskal, J B",
  abstract  = "Multidimensional scaling is the problem of representingn objects
               geometrically byn points, so that the interpoint distances
               correspond in some sense to experimental dissimilarities between
               objects. In just what sense distances and dissimilarities should
               correspond has been left rather vague in most approaches, thus
               leaving these approaches logically incomplete. Our fundamental
               hypothesis is that dissimilarities and distances are
               monotonically related. We define a quantitative, intuitively
               satisfying measure of goodness of fit to this hypothesis. Our
               technique of multidimensional scaling is to compute that
               configuration of points which optimizes the goodness of fit. A
               practical computer program for doing the calculations is
               described in a companion paper.",
  journal   = "Psychometrika",
  publisher = "Springer-Verlag",
  volume    =  29,
  number    =  1,
  pages     = "1--27",
  month     =  mar,
  year      =  1964,
  url       = "https://link.springer.com/article/10.1007/BF02289565",
  keywords  = "wiley-review-paper;high-dimensions",
  language  = "en",
  issn      = "0033-3123, 1860-0980",
  doi       = "10.1007/BF02289565"
}

@ARTICLE{Kruskal1964-gc,
  title    = "Nonmetric multidimensional scaling: A numerical method",
  author   = "Kruskal, J B",
  abstract = "We describe the numerical methods required in our approach to
              multi-dimensional scaling. The rationale of this approach has
              appeared previously.",
  journal  = "Psychometrika",
  volume   =  29,
  number   =  2,
  pages    = "115--129",
  month    =  jun,
  year     =  1964,
  url      = "https://doi.org/10.1007/BF02289694",
  keywords = "wiley-review-paper;high-dimensions",
  issn     = "0033-3123, 1860-0980",
  doi      = "10.1007/BF02289694"
}

@MISC{Rauber2009-kk,
  title        = "Multi-challenge Data Set",
  booktitle    = "Machine Learning Datasets",
  author       = "Rauber, Andreas",
  month        =  dec,
  year         =  2009,
  url          = "http://ifs.tuwien.ac.at/dm/dataSets.html",
  howpublished = "\url{http://ifs.tuwien.ac.at/dm/dataSets.html}",
  note         = "Accessed: 2020-9-17",
  keywords     = "wiley-review-paper;paper-tsne-liminal"
}

@ARTICLE{Chang2020-ry,
  title    = "shiny: Web Application Framework for {R}",
  author   = "Chang, Winston and Cheng, Joe and Allaire, J and Xie, Yihui and
              McPherson, Jonathan and {Others}",
  journal  = "R package version",
  volume   =  1,
  number   =  5,
  year     =  2020,
  url      = "https://CRAN.R-project.org/package=shiny",
  keywords = "wiley-review-paper;paper-tsne-liminal;interactive-graphics"
}

@MISC{Lyttle2020-dy,
  title    = "vegawidget: 'Htmlwidget' for 'Vega' and {'Vega-Lite'}",
  author   = "Lyttle, Ian and {Vega/Vega-Lite Developers}",
  year     =  2020,
  url      = "https://CRAN.R-project.org/package=vegawidget",
  keywords = "wiley-review-paper;paper-tsne-liminal;interactive-graphics"
}

@UNPUBLISHED{Laa2020-uv,
  title    = "Burning sage: Reversing the curse of dimensionality in the
              visualization of high-dimensional data",
  author   = "Laa, Ursula and Cook, Dianne and Lee, Stuart",
  abstract = "In high-dimensional data analysis the curse of dimensionality
              reasons that points tend to be far away from the center of the
              distribution and on the edge of high-dimensional space. Contrary
              to this, is that projected data tends to clump at the center.
              This gives a sense that any structure near the center of the
              projection is obscured, whether this is true or not. A
              transformation to reverse the curse, is defined in this paper,
              which uses radial transformations on the projected data. It is
              integrated seamlessly into the grand tour algorithm, and we have
              called it a burning sage tour, to indicate that it reverses the
              curse. The work is implemented into the tourr package in R.
              Several case studies are included that show how the sage
              visualizations enhance exploratory clustering and classification
              problems.",
  month    =  sep,
  year     =  2020,
  url      = "http://arxiv.org/abs/2009.10979",
  keywords = "wiley-review-paper;by-me"
}

@ARTICLE{Hotelling1933-of,
  title     = "Analysis of a complex of statistical variables into principal
               components",
  author    = "Hotelling, H",
  abstract  = "The problem is stated in detail, a method of analysis is derived
               and its geometrical meaning shown, methods of solution are
               illustrated and certain derivative problems are discussed. (To
               be concluded in October issue.) (PsycINFO Database Record (c)
               2016 APA, all rights reserved)",
  journal   = "J. Educ. Psychol.",
  publisher = "Warwick \& York",
  volume    =  24,
  number    =  6,
  pages     = "417",
  month     =  sep,
  year      =  1933,
  url       = "http://psycnet.apa.org/journals/edu/24/6/417",
  language  = "en",
  issn      = "0022-0663, 1939-2176",
  doi       = "10.1037/h0071325"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Donoho2000-fy,
  title     = "High-dimensional data analysis: The curses and blessings of
               dimensionality",
  booktitle = "{AMS} {CONFERENCE} {ON} {MATH} {CHALLENGES} {OF} {THE} {21ST}
               {CENTURY}",
  author    = "Donoho, David L",
  abstract  = "CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep
               Teregowda): The coming century is surely the century of data. A
               combination of blind faith and serious purpose makes our society
               invest massively in the collection and processing of data of all
               kinds, on scales unimaginable until recently. Hyperspectral
               Imagery, Internet Portals, Financial tick-by-tick data, and DNA
               Microarrays are just a few of the betterknown sources, feeding
               data in torrential streams into scientific and business
               databases worldwide. In traditional statistical data analysis,
               we think of observations of instances of particular phenomena
               (e.g. instance ↔ human being), these observations being a vector
               of values we measured on several variables (e.g. blood pressure,
               weight, height,...). In traditional statistical methodology, we
               assumed many observations and a few, wellchosen variables. The
               trend today is towards more observations but even more so, to
               radically larger numbers of variables -- voracious, automatic,
               systematic collection of hyper-informative detail about each
               observed instance. We are seeing examples where the observations
               gathered on individual instances are curves, or spectra, or
               images, or",
  year      =  2000,
  url       = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.329.3392",
  keywords  = "wiley-review-paper;high-dimensions"
}

@ARTICLE{Asimov1985-xr,
  title     = "{T}he {G}rand {T}our: {A} {T}ool for {V}iewing
               {M}ultidimensional {D}ata",
  author    = "Asimov, Daniel",
  abstract  = "The grand tour is a method for viewing multivariate statistical
               data via orthogonal projections onto a sequence of
               two-dimensional subspaces. The sequence of subspaces is chosen
               so that it is dense in the set of all two-dimensional subspaces.
               Desirable properties of such sequences of subspaces are
               considered, and several specific types of sequences are tested
               for rapidity of becoming dense. Tabulations are provided of the
               minimum length of a grand tour sequence necessary to achieve
               various degrees of denseness in dimensions up to 20.",
  journal   = "SIAM Journal of Scientific and Statistical Computing",
  publisher = "Society for Industrial and Applied Mathematics",
  volume    =  6,
  number    =  1,
  pages     = "128--143",
  month     =  jan,
  year      =  1985,
  url       = "http://dx.doi.org/10.1137/0906011",
  keywords  = "wiley-review-paper;high-dimensions",
  issn      = "0196-5204",
  doi       = "10.1137/0906011"
}

@INCOLLECTION{Buja2005-cx,
  title     = "Computational Methods for {High-Dimensional} Rotations in
               Data Visualization",
  booktitle = "Data Mining and Data Visualization",
  author    = "Buja, Andreas and Cook, Dianne and Asimov, Daniel and Hurley,
               Catherine",
  editor    = "Rao, C R and Wegman, E J and Solka, J L",
  abstract  = "There exist many methods for visualizing complex relations among
               variables of a multivariate dataset. For pairs of quantitative
               variables, the method of choice is the scatterplot. For triples
               of quantitative variables, the method of choice is 3D data
               rotations. Such rotations let us perceive structure among three
               variables as shape of point scatters in virtual 3D space.
               Although not obvious, three-dimensional data rotations can be
               extended to higher dimensions. The mathematical construction of
               high-dimensional data rotations, however, is not an intuitive
               generalization. Whereas three-dimensional data rotations are
               thought of as rotations of an object in space, a proper
               framework for their high-dimensional extension is better based
               on rotations of a low-dimensional projection in high-dimensional
               space. The term ``data rotations'' is therefore a misnomer, and
               something along the lines of ``high-to-low dimensional data
               projections'' would be technically more accurate. To be useful,
               virtual rotations need to be under interactive user control, and
               they need to be animated. We therefore require projections not
               as static pictures but as movies under user control. Movies,
               however, are mathematically speaking one-parameter families of
               pictures. This article is therefore about one-parameter families
               of low-dimensional projections in high-dimensional data spaces.
               We describe several algorithms for dynamic projections, all
               based on the idea of smoothly interpolating a discrete sequence
               of projections. The algorithms lend themselves to the
               implementation of interactive visual exploration tools of
               high-dimensional data, such as so-called grand tours, guided
               tours and manual tours.",
  publisher = "Elsevier",
  volume    =  24,
  pages     = "391--413",
  series    = "Handbook of Statistics",
  month     =  jan,
  year      =  2005,
  url       = "http://www.sciencedirect.com/science/article/pii/S0169716104240147",
  keywords  = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  issn      = "0169-7161",
  doi       = "10.1016/S0169-7161(04)24014-7",
  chapter = 14
}

@UNPUBLISHED{Laa2020-ni,
  title    = "{Hole or grain? A Section Pursuit Index for Finding Hidden
              Structure in Multiple Dimensions}",
  author   = "Laa, Ursula and Cook, Dianne and Buja, Andreas and Valencia,
              German",
  abstract = "Multivariate data is often visualized using linear projections,
              produced by techniques such as principal component analysis,
              linear discriminant analysis, and projection pursuit. A problem
              with projections is that they obscure low and high density
              regions near the center of the distribution. Sections, or slices,
              can help to reveal them. This paper develops a section pursuit
              method, building on the extensive work in projection pursuit, to
              search for interesting slices of the data. Linear projections are
              used to define sections of the parameter space, and to calculate
              interestingness by comparing the distribution of observations,
              inside and outside a section. By optimizing this index, it is
              possible to reveal features such as holes (low density) or grains
              (high density). The optimization is incorporated into a guided
              tour so that the search for structure can be dynamic. The
              approach can be useful for problems when data distributions
              depart from uniform or normal, as in visually exploring nonlinear
              manifolds, and functions in multivariate space. Two applications
              of section pursuit are shown: exploring decision boundaries from
              classification models, and exploring subspaces induced by complex
              inequality conditions from multiple parameter model. The new
              methods are available in R, in the tourr package.",
  month    =  apr,
  year     =  2020,
  url      = "http://arxiv.org/abs/2004.13327",
  keywords = "wiley-review-paper;high-dimensions"
}

@ARTICLE{Wickham2011-uz,
  title    = "{tourr}: An {R} Package for Exploring Multivariate Data with
              Projections",
  author   = "Wickham, Hadley and Cook, Dianne and Hofmann, Heike and Buja,
              Andreas",
  abstract = "This paper describes an R package which produces tours of
              multivariate data. The package includes functions for creating
              different types of tours, including grand, guided, and little
              tours, which project multivariate data (p-D) down to 1, 2, 3, or,
              more generally, d ($\leq$ p) dimensions. The projected data can
              be rendered as densities or histograms, scatterplots, anaglyphs,
              glyphs, scatterplot matrices, parallel coordinate plots, time
              series or images, and viewed using an R graphics device, passed
              to GGobi, or saved to disk. A tour path can be stored for
              visualisation or replay. With this package it is possible to
              quickly experiment with different, and new, approaches to tours
              of data. This paper contains animations that can be viewed using
              the Adobe Acrobat PDF viewer.",
  journal  = "Journal of Statistical Software, Articles",
  volume   =  40,
  number   =  2,
  pages    = "1--18",
  year     =  2011,
  url      = "http://www.jstatsoft.org/v40/i02/",
  keywords = "wiley-review-paper;paper-tsne-liminal;high-dimensions",
  issn     = "1548-7660",
  doi      = "10.18637/jss.v040.i02"
}

@ARTICLE{Laa2020-js,
  title         = "A slice tour for finding hollowness in high-dimensional data",
  author        = "Laa, Ursula and Cook, Dianne and Valencia, German",
  abstract      = "AbstractTaking projections of high-dimensional data is a
                   common analytical and visualisation technique in statistics
                   for working with high-dimensional problems. Sectioning, or
                   slicing, through high dimensions is less common, but can be
                   useful for visualising data with concavities, or non-linear
                   structure. It is associated with conditional distributions
                   in statistics, and also linked brushing between plots in
                   interactive data visualisation. This short technical note
                   describes a simple approach for slicing in the orthogonal
                   space of projections obtained when running a tour, thus
                   presenting the viewer with an interpolated sequence of
                   sliced projections. The method has been implemented in R as
                   an extension to the tourr package, and can be used to
                   explore for concave and non-linear structures in
                   multivariate distributions.",
  journal       = "J. Comput. Graph. Stat.",
  number        = "ja",
  pages         = "1--10",
  month         =  jun,
  year          =  2020,
  url           = "https://doi.org/10.1080/10618600.2020.1777140",
  keywords      = "wiley-review-paper;high-dimensions",
  archivePrefix = "arXiv",
  eprint        = "https://doi.org/10.1080/10618600.2020.1777140",
  primaryClass  = "stat.CO",
  arxivid       = "1910.10854",
  doi           = "10.1080/10618600.2020.1777140"
}

@ARTICLE{Cook2018-jm,
  title         = "{Dynamical projections for the visualization of {PDFSense}
                   data}",
  author        = "Cook, Dianne and Laa, Ursula and Valencia, German",
  abstract      = "A recent paper on visualizing the sensitivity of hadronic
                   experiments to nucleon structure (Wang et al. in
                   arXiv:1803.02777, 2018) introduces the tool PDFSense which
                   defines measures to allow the user to judge the sensitivity
                   of PDF fits to a given experiment. The sensitivity is
                   characterized by high-dimensional data residuals that are
                   visualized in a 3-d subspace of the 10 first principal
                   components or using non-linear embeddings. We show how a
                   tour, a dynamic visualisation of high dimensional data, can
                   extend this tool beyond 3-d relationships. This approach
                   enables resolving structure orthogonal to the 2-d viewing
                   plane used so far, and hence finer tuned assessment of the
                   sensitivity.",
  journal       = "The European Physical Journal C",
  volume        =  78,
  number        =  9,
  pages         = "742",
  month         =  sep,
  year          =  2018,
  url           = "http://dx.doi.org/10.1140/epjc/s10052-018-6205-2",
  keywords      = "wiley-review-paper;high-dimensions",
  archivePrefix = "arXiv",
  eprint        = "1806.09742",
  primaryClass  = "hep-ph",
  issn          = "1434-6052",
  arxivid       = "1806.09742",
  doi           = "10.1140/epjc/s10052-018-6205-2"
}

@BOOK{Xie2017-uh,
  title     = "Dynamic Documents with {R} and knitr",
  author    = "Xie, Yihui",
  abstract  = "Quickly and Easily Write Dynamic Documents Suitable for both
               beginners and advanced users, Dynamic Documents with R and
               knitr, Second Edition makes writing",
  publisher = "Chapman and Hall/CRC",
  edition   = "2nd",
  month     =  jul,
  year      =  2017,
  url       = "https://yihui.name/knitr/",
  address   = "Boca Raton, Florida",
  keywords  = "wiley-review-paper;misc",
  isbn      = "9781315382487, 9781315382487",
  doi       = "10.1201/9781315382487"
}

@BOOK{Chang2018-xl,
  title     = "{R} Graphics Cookbook: Practical Recipes for Visualizing Data
               (2nd edition)",
  author    = "Chang, Winston",
  publisher = "O'Reilly Media",
  year      =  2018,
  url       = "https://r-graphics.org",
  keywords  = "wiley-review-paper",
  isbn      = "9781491978603"
}

@BOOK{Xie2018-bg,
  title     = "{R} Markdown: The Definitive Guide",
  author    = "Xie, Yihui and Allaire, Joseph J and Grolemund, Garrett",
  publisher = "Chapman and Hall/CRC",
  year      =  2018,
  url       = "https://bookdown.org/yihui/rmarkdown",
  keywords  = "wiley-review-paper"
}

@ARTICLE{Wang2018-ng,
  title         = "{Mapping the sensitivity of hadronic experiments to nucleon
                   structure}",
  author        = "Wang, Bo-Ting and Hobbs, T J and Doyle, Sean and Gao, Jun
                   and Hou, Tie-Jiun and Nadolsky, Pavel M and Olness, Fredrick
                   I",
  journal       = "Phys. Rev. D",
  volume        =  98,
  number        =  9,
  pages         = "094030",
  year          =  2018,
  url           = "http://dx.doi.org/10.1103/PhysRevD.98.094030",
  keywords      = "wiley-review-paper",
  archivePrefix = "arXiv",
  eprint        = "1803.02777",
  primaryClass  = "hep-ph",
  arxivid       = "1803.02777",
  doi           = "10.1103/PhysRevD.98.094030"
}

@MISC{Google_Inc2020-yy,
  title        = "Quick, Draw! The Data",
  author       = "{Google, Inc}",
  abstract     = "What would you do with 50,000,000 drawings made by real
                  people on the internet?",
  year         =  2020,
  url          = "https://quickdraw.withgoogle.com/data",
  howpublished = "\url{https://quickdraw.withgoogle.com/data}",
  note         = "Accessed: 2020-4-23",
  keywords     = "wiley-review-paper"
}

@MISC{Coleman1986-so,
  title        = "Geometric Features of Pollen Grains",
  author       = "Coleman, David",
  year         =  1986,
  url          = "http://lib.stat.cmu.edu/data-expo/",
  howpublished = "\url{http://lib.stat.cmu.edu/data-expo/}",
  keywords     = "wiley-review-paper"
}

@INCOLLECTION{Steinbach2004-ta,
  title     = "The Challenges of Clustering High Dimensional Data",
  booktitle = "New Directions in Statistical Physics: Econophysics,
               Bioinformatics, and Pattern Recognition",
  author    = "Steinbach, Michael and Ert{\"o}z, Levent and Kumar, Vipin",
  editor    = "Wille, Luc T",
  publisher = "Springer Berlin Heidelberg",
  pages     = "273--309",
  year      =  2004,
  url       = "https://doi.org/10.1007/978-3-662-08968-2_16",
  address   = "Berlin, Heidelberg",
  keywords  = "wiley-review-paper",
  isbn      = "9783662089682",
  doi       = "10.1007/978-3-662-08968-2\_16"
}

@MANUAL{R_Core_Team2020-lr,
  title        = "R: A Language and Environment for Statistical Computing",
  author       = "{R Core Team}",
  year         =  2020,
  url          = "https://www.R-project.org/",
  address      = "Vienna, Austria",
  keywords     = "wiley-review-paper",
  organization = "R Foundation for Statistical Computing"
}

@ARTICLE{Ahn2010-jf,
  title    = "{The maximal data piling direction for discrimination}",
  author   = "Ahn, Jeongyoun and Marron, J S",
  journal  = "Biometrika",
  volume   =  97,
  number   =  1,
  pages    = "254--259",
  month    =  jan,
  year     =  2010,
  url      = "https://doi.org/10.1093/biomet/asp084",
  keywords = "wiley-review-paper",
  eprint   = "https://academic.oup.com/biomet/article-pdf/97/1/254/649953/asp084.pdf",
  issn     = "0006-3444",
  doi      = "10.1093/biomet/asp084"
}

@ARTICLE{Marron2007-ag,
  title     = "{Distance-Weighted} Discrimination",
  author    = "Marron, J S and Todd, Michael J and Ahn, Jeongyoun",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  102,
  number    =  480,
  pages     = "1267--1271",
  year      =  2007,
  url       = "http://www.jstor.org/stable/27639976",
  keywords  = "wiley-review-paper",
  issn      = "0162-1459"
}

@ARTICLE{Hall2005-du,
  title    = "Geometric representation of high dimension, low sample size data",
  author   = "Hall, Peter and Marron, J S and Neeman, Amnon",
  journal  = "J. R. Stat. Soc. Series B Stat. Methodol.",
  volume   =  67,
  number   =  3,
  pages    = "427--444",
  year     =  2005,
  url      = "https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2005.00510.x",
  keywords = "Chemometrics, Large dimensional data, Medical images,
              Microarrays, Multivariate analysis, Non-standard
              asymptotics;wiley-review-paper",
  eprint   = "https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2005.00510.x",
  issn     = "1369-7412",
  doi      = "10.1111/j.1467-9868.2005.00510.x"
}

@ARTICLE{Diaconis1984-mv,
  title     = "Asymptotics of Graphical Projection Pursuit",
  author    = "Diaconis, Persi and Freedman, David",
  journal   = "Ann. Stat.",
  publisher = "The Institute of Mathematical Statistics",
  volume    =  12,
  number    =  3,
  pages     = "793--815",
  month     =  sep,
  year      =  1984,
  url       = "https://doi.org/10.1214/aos/1176346703",
  keywords  = "wiley-review-paper",
  issn      = "0090-5364",
  doi       = "10.1214/aos/1176346703"
}

@BOOK{Bellman1961-tp,
  title    = "Adaptive control processes : a guided tour",
  author   = "Bellman, Richard",
  series   = "Princeton Legacy Library",
  year     =  1961,
  keywords = "wiley-review-paper",
  isbn     = "9780691652214"
}

@MANUAL{Wilke2019-qu,
  title    = "cowplot: Streamlined Plot Theme and Plot Annotations for
              'ggplot2'",
  author   = "Wilke, Clause O",
  year     =  2019,
  url      = "https://CRAN.R-project.org/package=cowplot",
  keywords = "wiley-review-paper"
}

@MANUAL{Eddelbuettel2020-ks,
  title    = "{RcppAnnoy}: 'Rcpp' Bindings for 'Annoy', a Library for
              Approximate Nearest Neighbors",
  author   = "Eddelbuettel, Dirk",
  year     =  2020,
  url      = "https://CRAN.R-project.org/package=RcppAnnoy",
  keywords = "wiley-review-paper"
}

@MANUAL{Beygelzimer2019-ju,
  title    = "{FNN}: Fast Nearest Neighbor Search Algorithms and Applications",
  author   = "Beygelzimer, Alina and Kakadet, Sham and Langford, John and Arya,
              Sunil and Mount, David and Li, Shengqiao",
  year     =  2019,
  url      = "https://CRAN.R-project.org/package=FNN",
  keywords = "wiley-review-paper"
}

@MANUAL{Krijthe2015-yz,
  title    = "{Rtsne}: {T-Distributed} Stochastic Neighbor Embedding using
              {Barnes-Hut} Implementation",
  author   = "Krijthe, Jesse H",
  year     =  2015,
  url      = "https://github.com/jkrijthe/Rtsne",
  keywords = "wiley-review-paper"
}

@MANUAL{Lee2020-ut,
  title    = "liminal: Multivariate Data Visualization With Tours and
              Embeddings",
  author   = "Lee, Stuart and Cook, Dianne",
  year     =  2020,
  url      = "https://github.com/sa-lee/liminal",
  keywords = "wiley-review-paper"
}

@article{Fisher1936,
author = {Fisher, R. A.},
title = {The Use of Multiple Measurements in Taxonomic Problems},
journal = {Annals of Eugenics},
volume = {7},
number = {2},
pages = {179-188},
doi = {https://doi.org/10.1111/j.1469-1809.1936.tb02137.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x},
abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
year = {1936}
}

@book{Tierney1991,
	Address = {New York, NY},
	Author = {Tierney, L.},
	Publisher = {Wiley},
	Title = {{L}isp{S}tat: {A}n {O}bject-{O}rientated
                  {E}nvironment for {S}tatistical {C}omputing and
                  {D}ynamic {G}raphics},
	Year = 1991}
	

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Tukey1983-fj,
  title       = "Some graphics for studying four-dimensional data",
  booktitle   = "Computer Science and Statistics: Proceedings of the 14th
                 Symposium on the Interface",
  author      = "Tukey, John W and Tukey, Paul A",
  publisher   = "Springer‐Verlag New York",
  volume      =  14,
  pages       = "60--66",
  institution = "Springer-Verlag New York",
  year        =  1983
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Tukey1983-fj,
  title       = "Some graphics for studying four-dimensional data",
  booktitle   = "Computer Science and Statistics: Proceedings of the 14th
                 Symposium on the Interface",
  author      = "Tukey, John W and Tukey, Paul A",
  publisher   = "Springer‐Verlag New York",
  volume      =  14,
  pages       = "60--66",
  institution = "Springer-Verlag New York",
  year        =  1983
}

@ARTICLE{Carr1987-mf,
  title     = "Scatterplot Matrix Techniques for Large {N}",
  author    = "Carr, D B and Littlefield, R J and Nicholson, W L and
               Littlefield, J S",
  abstract  = "[High-performance interaction with scatterplot matrices is a
               powerful approach to exploratory multivariate data analysis. For
               a small number of data points, real-time interaction is possible
               and overplotting is usually not a major problem. When the number
               of plotted points is large, however, display techniques that
               deal with overplotting and slow production are important. This
               article addresses these two problems. Topics include density
               representation by gray scale or by symbol area, alternatives to
               brushing, and animation sequences. We also discuss techniques
               that are generally applicable, including interactive graphical
               subset selection from any plot in a collection of scatterplots
               and comparison of scatterplot matrices.]",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  82,
  number    =  398,
  pages     = "424--436",
  year      =  1987,
  url       = "http://www.jstor.org/stable/2289444",
  issn      = "0162-1459",
  doi       = "10.2307/2289444"
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Inselberg1985-kf,
  title     = "The plane with parallel coordinates",
  author    = "Inselberg, Alfred",
  abstract  = "By means ofParallel Coordinates planar ``graphs'' of
               multivariate relations are obtained. Certain properties of the
               relationship correspond tothe geometrical properties of its
               graph. On the plane a point ←$\rightarrow$ line duality with
               several interesting properties is induced. A new duality
               betweenbounded and unbounded convex sets and hstars (a
               generalization of hyperbolas) and between Convex Unions and
               Intersections is found. This motivates some efficient Convexity
               algorithms and other results inComputational Geometry. There is
               also a suprising ``cusp'' ←$\rightarrow$ ``inflection point''
               duality. The narrative ends with a preview of the corresponding
               results inRN.",
  journal   = "Vis. Comput.",
  publisher = "Springer-Verlag",
  volume    =  1,
  number    =  2,
  pages     = "69--91",
  month     =  aug,
  year      =  1985,
  url       = "https://link.springer.com/article/10.1007/BF01898350",
  language  = "en",
  issn      = "0178-2789, 1432-2315",
  doi       = "10.1007/BF01898350"
}


@INCOLLECTION{Tukey1981-ov,
  title     = "Graphical display of data sets in three or more dimensions",
  booktitle = "Interpreting Multivariate Data",
  author    = "Tukey, P A and Tukey, J W",
  editor    = "Barnett, V",
  publisher = "Wiley",
  pages     = "189--213",
  year      =  1981
}


@ARTICLE{Wegman1990-dy,
  title     = "Hyperdimensional Data Analysis Using Parallel Coordinates",
  author    = "Wegman, Edward J",
  abstract  = "Abstract This article presents the basic results of using the
               parallel coordinate representation as a high-dimensional data
               analysis tool. Several alternatives are reviewed. The basic
               algorithm for parallel coordinates is laid out and a discussion
               of its properties as a projective transformation is given.
               Several duality results are discussed along with their
               interpretations as data analysis tools. Permutations of the
               parallel coordinate axes are discussed, and some examples are
               given. Some extensions of the parallel coordinate idea are
               given. The article closes with a discussion of implementation
               and some of my experiences.",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "Taylor \& Francis",
  volume    =  85,
  number    =  411,
  pages     = "664--675",
  month     =  sep,
  year      =  1990,
  url       = "http://www.tandfonline.com/doi/abs/10.1080/01621459.1990.10474926",
  issn      = "0162-1459",
  doi       = "10.1080/01621459.1990.10474926"
}


@article{spyrison_spinifex_2020,
	title = {spinifex: {An} {R} {Package} for {Creating} a {Manual} {Tour} of {Low}-dimensional {Projections} of {Multivariate} {Data}},
	volume = {12},
	issn = {2073-4859},
	shorttitle = {spinifex},
	url = {https://journal.r-project.org/archive/2020/RJ-2020-027/index.html},
	doi = {10.32614/RJ-2020-027},
	abstract = {Dynamic low-dimensional linear projections of multivariate data collectively known as tours provide an important tool for exploring multivariate data and models. The R package tourr provides functions for several types of tours: grand, guided, little, local and frozen. Each of these can be viewed dynamically, or saved into a data object for animation. This paper describes a new package, spinifex, which provides a manual tour of multivariate data where the projection coefﬁcient of a single variable is controlled. The variable is rotated fully into the projection, or completely out of the projection. The resulting sequence of projections can be displayed as an animation, with functions from either the plotly or gganimate packages. By varying the coefﬁcient of a single variable, it is possible to explore the sensitivity of structure in the projection to that variable. This is particularly useful when used with a projection pursuit guided tour to simplify and understand the solution. The use of the manual tour is applied particle physics data to illustrate the sensitivity of structure in a projection to speciﬁc variable contributions.},
	language = {en},
	number = {1},
	urldate = {2020-10-16},
	journal = {The R Journal},
	author = {Spyrison, Nicholas and Cook, Dianne},
	year = {2020},
	pages = {243},
	file = {Spyrison and Cook - 2020 - spinifex An R Package for Creating a Manual Tour .pdf:C\:\\Users\\spyri\\Zotero\\storage\\ZIA6NWQP\\Spyrison and Cook - 2020 - spinifex An R Package for Creating a Manual Tour .pdf:application/pdf},
}



@article{you_rdimtools_2020,
	title = {Rdimtools: {An} {R} package for {Dimension} {Reduction} and {Intrinsic} {Dimension} {Estimation}},
	shorttitle = {Rdimtools},
	journal = {arXiv preprint arXiv:2005.11107},
	author = {You, Kisung},
	year = {2020},
	file = {Full Text:C\:\\Users\\spyri\\Zotero\\storage\\QRC56DX3\\You - 2020 - Rdimtools An R package for Dimension Reduction an.pdf:application/pdf;Snapshot:C\:\\Users\\spyri\\Zotero\\storage\\AEVZNDND\\2005.html:text/html},
}

@book{pedersen_gganimate_2020,
	title = {gganimate: {A} {Grammar} of {Animated} {Graphics}},
	url = {https://CRAN.R-project.org/package=gganimate},
	author = {Pedersen, Thomas Lin and Robinson, David},
	year = {2020},
}

@book{sievert_interactive_2020,
	title = {Interactive {Web}-{Based} {Data} {Visualization} with {R}, plotly, and shiny},
	isbn = {978-1-138-33145-7},
	url = {https://plotly-r.com},
	publisher = {Chapman and Hall/CRC},
	author = {Sievert, Carson},
	year = {2020},
}

@article{cook_manual_1997,
	title = {Manual {Controls} for {High}-{Dimensional} {Data} {Projections}},
	volume = {6},
	issn = {1061-8600},
	url = {http://www.jstor.org/stable/1390747},
	doi = {10.2307/1390747},
	abstract = {Projections of high-dimensional data onto low-dimensional subspaces provide insightful views for understanding multivariate relationships. This article discusses how to manually control the variable contributions to the projection. The user has control of the way a particular variable contributes to the viewed projection and can interactively adjust the variable's contribution. These manual controls complement the automatic views provided by a grand tour, or a guided tour, and give greatly improved flexibility to data analysts.},
	number = {4},
	urldate = {2018-04-15},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Cook, Dianne and Buja, Andreas},
	year = {1997},
	pages = {464--480},
	file = {JSTOR Full Text PDF:C\:\\Users\\spyri\\Zotero\\storage\\9QIJC6VL\\Cook and Buja - 1997 - Manual Controls for High-Dimensional Data Projecti.pdf:application/pdf},
}


@book{rodrigues_lois_1840,
	title = {Des lois géométriques qui régissent les déplacements d'un système solide dans l'espace: et de la variation des cordonnées provenant de ces déplacements considérés indépendamment des causes qui peuvent les produire},
	shorttitle = {Des lois géométriques qui régissent les déplacements d'un système solide dans l'espace},
	author = {Rodrigues, Olinde},
	year = {1840},
}


@misc{li_toward_2020,
	title = {Toward {Comparing} {DNNs} with {UMAP} {Tour}},
	url = {https://tiga1231.github.io/umap-tour/},
	urldate = {2021-03-11},
	author = {Li, Mingwei and Scheidegger, Carlos},
	month = oct,
	year = {2020},
}

@article{RJ-2016-044,
  author = {Barret Schloerke and Hadley Wickham and Dianne Cook and
          Heike Hofmann},
  title = {{Escape from Boxland}},
  year = {2016},
  journal = {{The R Journal}},
  doi = {10.32614/RJ-2016-044},
  url = {https://doi.org/10.32614/RJ-2016-044},
  pages = {243--257},
  volume = {8},
  number = {2}
}


@ARTICLE{Wilkinson2009-pj,
  title     = "The History of the Cluster Heat Map",
  author    = "Wilkinson, Leland and Friendly, Michael",
  journal   = "The American statistician",
  publisher = "Taylor \& Francis",
  volume    =  63,
  number    =  2,
  pages     = "179--184",
  month     =  may,
  year      =  2009,
  url       = "https://doi.org/10.1198/tas.2009.0033",
  issn      = "0003-1305",
  doi       = "10.1198/tas.2009.0033"
}


@ARTICLE{Lee2020-kg,
  title         = "Casting Multiple Shadows: {High-Dimensional} Interactive
                   Data Visualisation with Tours and Embeddings",
  author        = "Lee, Stuart and Laa, Ursula and Cook, Dianne",
  month         =  dec,
  year          =  2020,
  url           = "http://arxiv.org/abs/2012.06077",
  archivePrefix = "arXiv",
  eprint        = "2012.06077",
  primaryClass  = "stat.OT",
  arxivid       = "2012.06077"
}

@misc{ASASGVL,
  author = {{ASA Statistical Graphics Section}},
  title = {{Video Library}},
  year = 2021,
  howpublished = {\url{https://community.amstat.org/jointscsg-section/media/videos}}}

@InProceedings{Wegman92,
author="Wegman, Edward J.",
editor="Page, Connie
and LePage, Raoul",
title="The Grand Tour in k-Dimensions",
booktitle="Computing Science and Statistics",
year="1992",
publisher="Springer New York",
address="New York, NY",
pages="127--136",
abstract="The grand tour introduced by Asimov (1985) is based on the idea that one method of searching for structure in d-dimensional data is to ``look at it from all possible angles,'' more mathematically, to project the data sequentially in to all possible two-planes. The collection of two-planes in a d-dimensional space is called a Grassmannian manifold. A key feature of the grand tour is that the projection planes are chosen according to a dense, continuous path through the Grassmannian manifold which yields the visual impression of points moving continuously.",
isbn="978-1-4612-2856-1"
}

@article{Martinez2013,
author = {Martinez, Wendy L.},
title = {Image grand tour},
journal = {WIREs Computational Statistics },
volume = {5},
number = {3},
pages = {198-206},
keywords = {grand tour, exploratory data analysis, image fusion, remote sensing, pixel tour},
doi = {https://doi.org/10.1002/wics.1253},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1253},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1253},
abstract = {Abstract We describe a method of fusing, visualizing, and exploring multiple registered images called the image grand tour (IGT). The IGT is based on the grand tour idea for exploring high-dimensional data sets. In this article, we provide information on the general grand tour and show how this can be adapted to explore many linear combinations of the registered images in search of interesting structure and information. We provide several examples where the IGT is used for remote sensing, the search for rock art pictographs, and sensor fusion. WIREs Comput Stat 2013, 5:198–206. doi: 10.1002/wics.1253 This article is categorized under: Statistical Learning and Exploratory Methods of the Data Sciences > Exploratory Data Analysis Statistical Learning and Exploratory Methods of the Data Sciences > Image Data Mining Applications of Computational Statistics > Signal and Image Processing and Coding},
year = {2013}
}

@article{Moustafa2010,
author = {Moustafa, Rida E.},
title = {Pseudogrand tour},
journal = {WIREs Computational Statistics },
volume = {2},
number = {6},
pages = {711-718},
keywords = {interactive visualization, space transformed visualization, exploratory data analysis, density estimation},
doi = {https://doi.org/10.1002/wics.133},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.133},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.133},
abstract = {Abstract The pseudogrand tour (PGT) is an approximate version of the grand tour (GT), and an example of the dynamic data visualization methods that assist in exploring hyperdimensional data through a continuous sequence of lower dimensional projections. The PGT adds the time dimensionality to the visualization process which in turn increases the human interaction with the data and reveals comprehensive views of the data. The PGT has some clear advantage suitable for the dynamic data visualization—such as the fast and easy computation, can be constructed using many orthogonal bases (interpolation functions), and the flexibility to visualize the projections as a sequence of scatterplot frames changing over time or a static profile plots of interpolated projections. This article focuses on the implementations of the PGT, the use of interpolation functions, the extensions to higher dimensions, and the scalability to large data points. WIREs Comp Stat 2010 2 711–718 DOI: 10.1002/wics.133 This article is categorized under: Statistical Learning and Exploratory Methods of the Data Sciences > Exploratory Data Analysis Statistical and Graphical Methods of Data Analysis > Statistical Graphics and Visualization},
year = {2010}
}

@article{Moustafa2009,
author = {Moustafa, Rida E. and Hadi, Ali S.},
title = {Grand tour and the Andrews plot},
journal = {WIREs Computational Statistics },
volume = {1},
number = {2},
pages = {245-250},
doi = {https://doi.org/10.1002/wics.30},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.30},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.30},
abstract = {Abstract The relationship between Andrews plot and Grand Tour (GT) stems from the fact that both view multiprojections of hyperdimensional data. The difference, however, is that GT views all possible projections of the data, while Andrews plot views only sets of projections. In this paper, we give a quick introduction to GT and Andrews plot and some visualization examples. Copyright © 2009 John Wiley \& Sons, Inc. This article is categorized under: Statistical and Graphical Methods of Data Analysis > Statistical Graphics and Visualization},
year = {2009}
}

@article{Swayne2003,
	Author = {Deborah F. Swayne and Duncan Temple Lang and Andreas Buja and Dianne Cook},
	Issue = {4},
	Journal = {Journal of Computational Statistics and Data Analysis},
	Note = {http://authors.elsevier.com/sd/article/S0167947302002864},
	Pages = {423--444},
	Title = {GGobi: Evolving from XGobi into an Extensible Framework for Interactive Data Visualization},
	Volume = {43},
	Year = 2003
}
	
@article{Sutherland2000,
	Author = {Sutherland, P. and Rossini, A. and Lumley, T. and
                  Lewin-Koh, N. and Dickerson, J. and Cox, Z. and
                  Cook, D.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {3},
	Pages = {509--529},
	Title = {Orca: {A} {V}isualization {T}oolkit for
                  {H}igh-{D}imensional {D}ata},
	Volume = {9},
	Year = 2000
}

@article{Swayne1998,
	Author = {Swayne, D. F. and Cook, D. and Buja, A.},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = 1,
	Pages = {113--130},
	Title = {{XG}obi: {I}nteractive {D}ynamic {G}raphics in the
                  {X} {W}indow {S}ystem},
	Volume = 7,
	Year = 1998
}

@article{Xie2014,
author = {Yihui Xie and Heike Hofmann and Xiaoyue Cheng},
title = {{Reactive Programming for Interactive Graphics}},
volume = {29},
journal = {Statistical Science},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {201 -- 213},
keywords = {interactive graphics, R language, Reactive programming},
year = {2014},
doi = {10.1214/14-STS477},
URL = {https://doi.org/10.1214/14-STS477}
}

@article{JSSv081i05,
   author = {Mark O'Connell and Catherine B. Hurley and Katarina Domijan},
   title = {Conditional Visualization for Statistical Models: An Introduction to the condvis Package in R},
   journal = {Journal of Statistical Software, Articles},
   volume = {81},
   number = {5},
   year = {2017},
   keywords = {interactive; graphics; regression; classification; blackbox models},
   abstract = {The condvis package is for interactive visualization of sections in data space, showing fitted models on the section, and observed data near the section. The primary goal is the interpretation of complex models, and showing how the observed data support the fitted model. There is a video accompaniment to this paper available at https: //www.youtube.com/watch?v=rKFq7xwgdX0.},
   issn = {1548-7660},
   pages = {1--20},
   doi = {10.18637/jss.v081.i05},
   url = {https://www.jstatsoft.org/v081/i05}
}

