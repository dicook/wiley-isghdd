---
author:
  - name: Stuart Lee
    affiliation: Monash University
    # use this syntax to add text on several lines
    address: |
      | Department of Econometrics and Business Statistics, Monash University
    email: stuart.a.lee@monash.edu
  - name: Ursula Laa 
    affiliation: University of Natural Resources and Life Sciences
    address:  |
      | Institute of Statistics, University of Natural Resources and Life Sciences
    email:  ursula.laa@boku.ac.at
  - name: Natalia da Silva
    address: |
      | Instituto de Estadística (IESTA), Universidad de la República
    affiliation: Universidad de la República
    email: natalia@iesta.edu.uy
  - name: Nicholas Spyrison
    address: |
      | Faculty of Information and Technology, Monash University
    affiliation: Monash University
    email: nicholas.spyrison@monash.edu
  - name: Dianne Cook
    address: |
      | Department of Econometrics and Business Statistics, Monash University
    affiliation: Monash University
    email: dicook@monash.edu
  - name: Earo Wang
    address: |
      | Department of Statistics, The University of Auckland
    affiliation: The University of Auckland
    email: earo.wang@auckland.ac.nz
  - name: H. Sherry Zhang
    address: |
      | Department of Econometrics and Business Statistics, Monash University
    affiliation: Monash University
    email: huize.zhang@monash.edu
title:
  formatted: "An Overview of Tours for Dynamic Visualisation of High-dimensional Data"
abstract: > 
  This article discusses a high-dimensional visualization technique called the tour, which can be used to view data in more than three dimensions. We review the theory and history behind the technique, as well as modern software developments and applications of the tour that are being found across the sciences and machine learning. 
keywords:
  formatted: ["tours", "data visualization", "high-dimensional data", "data science", "exploratory data analysis"]
output: 
  bookdown::pdf_document2:
    template: template/wires_template_rmd.tex
    keep_tex: true
    toc: false
bibliography: references.bib
biblio-style: apalike
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  fig.show = 'hold',
  dpi = 300 #,
  # out.width = "\\textwidth",
  # fig.path = here::here('img/')
)
```

<!--
Writing style: third person (it was done, ...)
-->

# Introduction

<!-- Purpose/why and what is high-d data (Di)-->

Data commonly arrives with more than two measured variables, which makes it more complicated to plot on a page. With multiple variables, especially if there is some association between variables, this would be called multivariate or high-dimensional data. When the variables are all numeric, or quantitative, visualisation often relies on some form of dimension reduction. This can be done by taking linear projections, for example, principal component analysis [@Hotelling1933-of] or linear discriminant analysis [@Fisher1936]. It is also common to reduce dimension nonlinearly with techniques like multidimensional scaling (MDS) [@Kruskal1964-do] or t-Distributed Stochastic Neighbour Embedding (t-SNE) [@Van_der_Maaten2008-qa]. 

> Maybe we should clarify What is high-dimensional data? here

The term "high-dimensional" here means Euclidean space. Figure \ref{fig:cubes} shows a way to imagine this. It shows a sequence of cube wireframes, ranging from 1D through to 6D, where beyond 2D is a linear projection of the cube. As dimension increase, a new orthogonal axis is added. For cubes, this is achieved by doubling the cube: a 2D is two 1D cubes, a 3D is two 2D cubes, and so forth. 

\begin{figure*}[!h]
\centerline{\includegraphics[width=0.95\textwidth]{figures/cubes.png}}
\caption{Illustrating what is meant by "high-dimensional" in this paper, and a "linear projection". From a sequence of increasing dimension cubes, from 1D to 6D, as wireframes, it can be seen that the as dimension increase by 1, the cube doubles}
\label{fig:cubes}
\end{figure*}

The focus of this review will be on visualising high-dimensional data using linear projections, in particular, as provided by the grand tour [@Asimov1985-xr; @Buja2005-cx]. The reason being that it is not feasible to adequately the very large area of visualising high-dimensions, and there have been numerous developments in tours recently.  An overview of the technique, and new modifications is provided, along with how these techniques can be used in a variety of applications, and to help understand nonlinear dimension reduction results.  

A tour can be considered to be a dynamic graphic, because it shows a smooth sequence of projections over time, ideally with controls that allow stopping, reversing, changing direction, or going forward again. It can be useful to embed a tour into an interactive graphics system, where plots can be queried and elements highlighted (see for e.g. @Swayne2003-cc or @Tierney1991). To create the smooth sequence, a geodesic interpolation is computed between consecutive frames.  It allows the viewer to extrapolate from the low-dimensional to  shapes corresponding to multivariate distribution, and is particularly useful for detecting clusters, outliers and non-linear dependence. 

Nonlinear dimension reduction techniques such as t-SNE have become very popular in recent years, primarily for the ability to capture cluster structure in a succinct visual summary. However, it is only a summary, and it likely involves substantial warping of the original data space. Using the tour along with these techniques can illuminate the nature of the warped space, and reveal other structure lost in the dimension reduction.  Figure \ref{fig:tsne-tour} illustrates the difference in what can be learned from a tour in comparison with nonlinear dimension reduction using t-SNE. The 10-dimensional data comes from @Rauber2009-kk. The t-SNE view (plot A) shows six clearly separated clusters, all spherical with different sizes. The tour shows that the clusters look very little like this in the full data space. The clusters are at various distances apart and very different sizes. In the four projections from the tour this can be seen. The two green clusters are large and spherical, and far from the brown clusters. The brown clusters have one larger one, and three smaller, very close to each other. All of these are elliptical, which means that they have very little variability, actually no variability if you watch the full tour, in some of the 10 dimensions. This gives some deeper perspective to what is learned from t-SNE, and illustrates what the t-SNE dimension reduction has done: it has found small gaps between points and expanded these gaps to yield the representation. It should be noted, though, that the t-SNE view clearly reveals the presence of six distinct clusters. With this information is the invitation to look closer at the data in the tour, to see, that yes, indeed, there are three, tiny, tiny clusters very close to each other.

\begin{figure*}[!t]
         \includegraphics[width=0.5\textwidth]{figures/cluster_example_r.pdf}
     \vfill
   \begin{minipage}{\linewidth}     
   \centering
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour1_r.pdf}
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour2_r.pdf}
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour3_r.pdf}
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour4_r.pdf}
   \end{minipage}%
\caption{Comparison of structure perception between nonlinear dimension reduction using t-SNE (A) and projections seen during a tour (B.1-4). There are six clusters, as seen in the t-SNE view, but the relative distance between the clusters is extremely varied. This can be seen in the tour projections. The two green clusters are spherical in shape, and very distance from the brown clusters. Three of the brown clusters are very close to each other (just visible in B.1), and all brown clusters are elliptical. The tour provides a more accurate rendering of the clusters in the high-dimensional space, and complements what is learned from the dimension reduction.}
\label{fig:tsne-tour}
\end{figure*}

While tours are invaluable for assessing the geometry of data, they are by no means the only technique available for visualising structure in high dimensional data. An early technique proposed for assessing pairwise relationships between variables is the scatter plot matrix (SPLOM) [@Tukey1983-fj] <!-- there might be others here(?) -->. In this graphic, the canvas is split into a matrix where each off-diagonal element is a scatter plot of variable pairs, while the diagonal elements are either left blank or represent univariate structure. The SPLOM allows the viewer to assess correlation structure but does not scale to large numbers of variables. 

Similarly, parallel coordinates plots (PCP) can be used to explore correlation and co-linearities in multivariate data [@Inselberg1985-kf]. In PCPs, variables are arranged along the (vertical) horizontal axis with vertical (horizontal) axes drawn representing the range of values for each variable. Points (observations) of the data are represented by drawing lines between each variables axis. If there is positive correlation between two variables the lines will be parallel, while for negative correlation the lines will cross. By placing multiple variables side by side in a PCP higher order structure like clustering or lower dimensional embeddings is revealed, however the ordering of variables is important to reveal these features. 

The heatmap display is widely used to visualise cluster structure in bioinformatics. In a heatmap each element of a numeric matrix is displayed as a single colored square pixel on the canvas. The hue of the color is mapped to the magnitude of the element's values. A subtlety of using the heatmap is determining how to order the rows and columns of the matrix called seriation. In practice, two way hierarchical clustering  or singular value decomposition is used to order rows and columns. See @Wilkinson2009-pj for a comprehensive history.



<!-- Original tours (Di)
Not sure how much of this wee need to go into...
- subplots trellis literature
- data pipelines (?)
- What do we mean by multivariate data visualisation?
- multivariate categorical vis, tree maps etc.
-->

The rest of the review is structured as follows: in section \@ref(notation) we define the notation and components of a tour display. By its nature a tour is most effective to analyst when combined with interactivity; in section \@ref(interaction) we review the components of user interfaces for manipulating tour views. The implementation of tour paths in statistical software is reviewed in section \@ref(software), where we discuss the history and state of the art packages for computing them. Section \@ref(applications) shows the diverse applications of the tour in the natural sciences, machine learning and applied statistics. Finally, in section \@ref(discussion) we point to future research directions for tours. 

# Tours for high dimensional visualization {#notation}

- Bases notation (Sherry)

Some notations are defined for describing $d$-dimensional projections in $p$-dimensional space. Let $X_{n \times p}$ be the original data whose projections are of our interest. A projection basis, $A_{p \times d}$, characterises the direction from which the high-dimensional data are projected. Projection bases needs to satisfy an orthonormality condition, which requires each axis to be unit vector and perpendicular to each other, and this gives the basis space a geometrical structure of a Stiefel manifold. With a data matrix and a projection basis, a projection can be defined as $Y = X \cdot A$ for visual inspection.

> figure 2 diagram illustrating a projection: Di thinks making a Huber plot (2D data - 1D projection) here with projected data on a couple of directions is ideal

# ```{r}
# PPtreeViz::Huberplot(iris[,1:2],iris[,5],PPmethod="LDA")
# ```

- Display (Sherry)

Various displays are available to show projections in 1D, 2D, or higher dimensions. A 1D projection shows the data in a histogram as if a hand shadow being projected onto a wall. Two-d projections are usually displayed with scatterplot since it is the most common plot for showing bivariate relationship. Higher dimensional projections can be shown with multivariate display like scatterplot matrix or parallel coordinates plot. Figure <!--figure 3 --> shows a 1D display with histogram, a 2D display with scatterplot, and a 5D display with a parallel coordinates plot. More display methods can be found in [@Wickham2011-uz].

grand tour, random, may miss interesting, take long to rotate to that specific angle, guided tour, along with projection pursuit, by generating target bases, interestingness

> figure 3 diagram illustrating different displays for different d

- Choosing targets, inc pp indexes (Sherry)

To define whether a projection is interesting or not in the guided tour, an index function is used. An index function defines a surjection function from the projection $Y$ in $\mathbb{R}^{n \times d}$ to a scalar in $\mathbb{R}$. For the high-dimensional data, an interesting projection is the one that deviates from normality, as discussed in @Diaconis1984-mv and @Huber1985-zq [expand more here]. Numerous index functions have been developed since the initial index proposed by @Friedman1974-ck: <!-- entropy-based index? --> holes and central mass index [@Cook2008-nl] computes the deviation of the projected data from a normal distribution; @Posse1995-ih proposed a chi-square index for detecting the spiral structure in the data;  kurtosis and skewness indices are raised in @Loperfido2020-xj and @Loperfido2018-ga to detect outliers in financial time series; and most recently, scagnostic indices [@Laa2020-zj] provides eight measures for summarising information between pairs of variables in scatter plot matrices. 

> figure 4 diagram illustrating different types of target generation

- Geodesic interpolation (Ursula)

The smooth animation between the selected target frame is generated via a step-wise rotation in the high-dimensional space. Different methods to derive this rotation were described in @Buja2005-cx, and we can distinguish two types of interpolation. When interpolating between frames we rotate the starting basis onto the exact basis representation selected as a basis, and @Buja2005-cx describes three different methods to achieve this (based on decompositions of orthogonal matrices, Givens decompositions, or Householder decompositions). Alternatively, when interpolating between planes the rotation is constructed towards any basis that represents the plane corresponding to the target frame, such that it follows the shortest path, i.e. the geodesic, avoiding any in-plane rotation. The geodesic interpolation is derived using singular value decomposition and is implemented in the `tourr` package.

Typically the geodesic interpolation is preferred, since within-plane rotation is distracting and does not provide new information. An exception might be the case of a projection pursuit guided tour with an index function that is sensitive to these rotations [@Laa2020-zj].

For any method we need to ensure that each projection along the interpolated path is still orthonormal. In the case of one-dimensional projections, the set of bases traces a path along the surface of a hypersphere of radius one, as illustrated in Figure (XXX adding an illustration using ferrn). For higher-dimensional projections this is generalised and we find the path along the surface of a torus instead (need to check about this with Sherry).

> figure 5 diagram illustrating geodesic interpolation

- Slices vs projections (Ursula)

Projections can hide certain features, sections can provide additional information @Furnas1994-dz
Sectioning a high-dimensional space in systematic manner is challenging, there are a lot of choices we need to make
Typical approach is interactive: brushing to select sections in one view, highlight points in a second view, e.g. a tour display
Slice tour approach: use distance from the projection plane (through a selected center point), update the section systematically with the projection plane @Laa2020-js
Summary of applications: viewing geometric shapes, model visualization
Connection with projection pursuit: section pursuit @Laa2020-ni

\begin{figure*}
   \centering
         \includegraphics[width=0.9\textwidth]{figures/slice_tour_left.jpg}
         \includegraphics[width=0.9\textwidth]{figures/slice_tour_right.jpg}
\caption{Ursula to write}
\label{fig:tour-slice}
\end{figure*}


- Transformations on projections (Ursula)

Transformations of the data are common in the preprocessing, but sometimes we want to transform the data after projecting onto lower dimensions
Example would be to address piling effects that are a result of projecting form high-dimensional space down to low-dimensions
A solution to this problem was presented in the sage display @Laa2020-uv and is using a radial transformation of the projected data to avoid piling near the center
Summary of applications: better understanding of clustering in high-dimensional space (discussed below), resolving small features near the center

\begin{figure*}
   \centering
         \includegraphics[width=0.9\textwidth]{figures/laa_radial_transformation.pdf}
\caption{An illustration of the radial transformation. Each panel represents linear projections of $p$ dimensional equidistant circles. As $p$ increases the circles get pushed further to the edge.}
\label{fig:tour-transformation}
\end{figure*}

# Ways of interacting {#interaction}

## Basic Interactions

- Stop/start/reverse (Stuart)

\begin{figure*}
   \centering
         \includegraphics[width=0.9\textwidth]{figures/liminal-stop-pause-refresh.png}
\caption{The clustering example from Figure \ref{fig:tsne-tour} using the liminal interface. Here a grand tour is displayed on the right hand side, with buttons allowing users to play, pause and refresh the tour animation.}
\label{fig:tour-controls}
\end{figure*}

## Manual tour (Nick)

Manual tours [@cook_manual_1997; @spyrison_spinifex_2020] offer a means to interactively control the contribution of a single variable on the projection plane. This is particularly useful for exploring a projection once a feature of interest has been identified. Manual tours can then be employed to explore local area of, or test the structure of the feature, with respect to a selected variable.

The details of performing a manual tour are described by @spyrison_spinifex_2020, but high-level unit-interaction between each frame is as follows:

__Input:__ Starting basis, manipulation variable, an in-plane rotation angle -- $\theta$, an out-of-plane rotation angle -- $\phi$  $\\$
__Output:__ Rotated basis $\\$
__Steps:__

1. Initialise a manipulation dimension onto the start basis. Given the manipulation variable a full contribution and orthonormalise this space. 
2. Post-multiply the space, by a rotation matrix, as solved for in application of Rodrigues’ formula [@rodrigues_lois_1840].
3. Truncate the manipulation dimension.

Figure \ref{fig:manual-tour} illustrates the manual tour, by radially manipulating the contribution of variable that is crucial, to explain the separation of a particular cluster. To start we first identify a basis by orthonormalising the linear discriminant. We select a variable that has a large contribution in the basis, and watch a continuous animation as this variable is rotated fully into the projection, compeletely out of the projection, and then returned to it's original contribution.

```{r manual-tour, out.width="100%", fig.show='asis', fig.cap='Manual tour of flea data. We initalise the start basis to the linear discriminant analysis and select the variable with the largest contribution separating the cluster shown as green circles. By controlling the contribution of the variable we see that it is quite sensitive to the sepration of this cluster.', eval=FALSE}
if(F) ## Creation and saving figure at:
  file.edit("./R/make_radial_tour_fig.r")
knitr::include_graphics("./figures/fig_radial_manual_tour.png")
```


\begin{figure*}[!ht]
   \centering
         \includegraphics[width=0.32\textwidth]{figures/penguins_manual_bl1_r.pdf}
         \includegraphics[width=0.32\textwidth]{figures/penguins_manual_bl3_r.pdf}
         \includegraphics[width=0.32\textwidth]{figures/penguins_manual_bl4_r.pdf}
\caption{Four projections from a manual tour where variable "bl" is being rotated out of the projection (orange line). When this variable is removed the two light green clusters merge, which informs us that "bl" is an important variable for distinguishing between these two groups.}
\label{fig:manual-tour}
\end{figure*}


- Linked brushing (Earo)

> something from ggobi book

* Brushing as database query
* Brushing as conditioning
* Brushing as geometric sectioning
* Persistent vs. transient 

> > figure 10: plots showing example

- Spin-and-brush  (Ursula)

Tour for visual cluster analysis, identification of outlying points
Maybe the physics example from the ggobi book: find group in one view, highlight, restart tour, and so on, in the end we can review the tour with groups highlighted in colour to get an overview of how the data clusters
Requires persistent brushing with multiple groups

\begin{figure}[htp]
\centerline{{\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp1.pdf}}
 {\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp2.pdf}}
 {\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp5.pdf}}}
\smallskip
\centerline{{\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp7.pdf}}
 {\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp8.pdf}}
 {\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp9.pdf}}}
\centerline{{\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp10.pdf}}
  {\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp11.pdf}}
  {\includegraphics[width=0.32\textwidth]{figures/ggobi_book/prim7-pp13.pdf}}}
\caption{Spin and brush reprinted from ggobi book}
\label{prim7-tour}
\end{figure}


# Software {#software}

- Dataviewer, XGobi, GGobi, cranvas (XLispStat, Orca, mmvz) (Di)

- tourr (Di) 
- spinifex (Nick)

The R package spinifex [@spyrison_spinifex_2020] has 3 primary features: it produces manual tours (predefined path or interactive manipulation, identifies orthonormal global feature bases with the use of the Rdimtools [@you_rdimtools_2020] package, renders (manual or other) tours as animations exportable to static .gif (gganimate [@pedersen_gganimate_2020] package) or interactive .html widgets (plotly [@sievert_interactive_2020] package), lastly it offers interactive shiny application that offers an graphical user interface to quickly sample tour features.

- liminal (Stuart)

The liminal R package uses the tour to explore the quality of non-linear dimensionality reduction algorithms. The interface consists of two side by side views consisting of a scatter plot displaying a reduced form of the data, and an interactive tour. Controls such as play/stop/restart are implemented allowing a user to pause on interesting projections and return them to their R session for further analysis. Linked brushing is implemented on both views - if a users brush on the scatter plot view they can see if and how an algorithm like t-SNE has distorted distances in higher dimensional space, while if they brush on the tour view, the tour is paused and structure like cluster separation can be ascertained.      


- python (Di to follow up with Csaba)

# Applications {#applications}

- Model vis examples eg random forest (from Hadley, removing the blindfold) (Natalia)

> figure 12 tour plot(s) of vote matrix and tour plot(s) of variables, with some annotation of cases?

- Physics (Ursula)

Physics models often consider $\mathcal{O}(10)$ free parameters and are compared to a much larger number of experimental observables ($\mathcal{O}(100)$). The comparison typically relies on numeric computation of the model predictions for all observables, potentially obscuring the nature of their dependence on the model parameters. Here, multivariate visualisation methods can provide new insights. This was demonstrated in @Cook2018-jm. For example, we explored grouping of experiments based on how they constrain the parameter space and we also identified an interesting multivariate outlier that pointed to potential issues with the data point. For illustration we show static views from the tour showing the orthogonal structure of the three groups (indicated by color), and a display which highlights the outlyingness of the data point marked with an asterisk symbol in Fig. \ref{fig:physics}.

\begin{figure*}
  \centering
           \includegraphics[width=0.45\textwidth]{figures/allcenter-301.png}
         \includegraphics[width=0.45\textwidth]{figures/jetCluster-027.png}


\caption{Selected frames from using a grand tour of the physics data. Left: the three different types of measurements (shown in different colors) are aligned along different directions in parameter space. Right: an outlying point is marked with an asterisk symbol in the ATLAS7new facet.}
\label{fig:physics}
\end{figure*}


- Bioinformatics (Stuart)

In single cell RNA sequencing, scientists are interested in identifying novel cell types and understanding the relationships between cells or their developmental trajectory. To achieve this they perform cluster analysis on a counts matrix or principal components and embed the results via t-SNE and label points according the cluster label. One of the main advantages of t-SNE is the avoidance of over-plotting so clusters can be clearly identified on a scatter plot, however, this can come at the cost of interpretability as global distances are distorted.  In @Laa2020-uv, we used radial transformations of the tour projections as an alternative to t-SNE that better preserves global structure while still retaining cluster topology.

\begin{figure*}
  \centering
           \includegraphics[width=0.24\textwidth]{figures/mouse_sage_2c_gam3-001.png}
         \includegraphics[width=0.24\textwidth]{figures/mouse_sage_2c_gam3-016.png}
         \includegraphics[width=0.24\textwidth]{figures/mouse_sage_2c_gam3-038.png}
         \includegraphics[width=0.24\textwidth]{figures/mouse_sage_2c_gam3-074.png}

\caption{Selected frames from using a grand tour of mouse retina single cell RNA-seq data with the radial transformation. The sage display was used to identify and verify cluster sepearation between the three highlighted clusters estimated from a clustering algorithm.}
\label{fig:mouse-cluster}
\end{figure*}

- High-d shapes/distributions: normal, skewed, outliers, (Di from tutorial notes)

> figure 15

- neural networks (this could go into model vis?)

The grand tour along with direct interaction techniques has been proposed as a technique for understanding the training of deep neural network models [@Li2020-kg]. They proposed a novel method for aligning the output of different layers by interpolating the output of different layers of a deep neural network via the the grand tour. They also apply the grand tour to explore the changes in single layers of the network for each training epoch. For example, by the running tour over the softmax layer outputs of a classification model, an analyst may understand where in the training confusion between classes occur and gain a view of model performance. Similarly, the difference between training and test sets can be assessed through side by side linked tours of layer outputs. @li_toward_2020 extends this idea by first reducing the dimensionality of output layers with UMAP and then using the grand tour with manual controls over 15 dimensional embeddings to understand layer topology.

\begin{figure*}
   \centering
         \includegraphics[width=0.45\textwidth]{figures/scheidigger_nn_tour.png}
          \includegraphics[width=0.45\textwidth, keepaspectratio=true]{figures/scheidigger_umap_tour.png}
\caption{Left: A grand tour run on the output of a deep neural network model for classification. Right: A grand tour on UMAP components of a layer of deep neural network.}
\label{fig:tour-nn}
\end{figure*}

# Discussion {#discussion}

* why tours are useful and what do we learn from them?
* what research is needed?


# References {-}
