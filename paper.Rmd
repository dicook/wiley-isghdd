---
author:
  - name: Stuart Lee
    affiliation: Monash University
    # use this syntax to add text on several lines
    address: |
      | Department of Econometrics and Business Statistics,
      | Monash University
    email: stuart.a.lee@monash.edu
  - name: Ursula Laa 
    affiliation: University of Natural Resources and Life Sciences
    address:  |
      | Institute of Statistics,
      | University of Natural Resources and Life Sciences
    email:  ursula.laa@boku.ac.at
  - name: Natalia da Silva
    address: |
      | Instituto de Estadística (IESTA), 
      | Universidad de la República
    affiliation: Universidad de la República
    email: natalia@iesta.edu.uy
  - name: Nicholas Spyrison
    address: |
      | Faculty of Information and Technology 
      | Monash University
    affiliation: Monash University
    email: nicholas.spyrison@monash.edu
  - name: Dianne Cook
    address: |
      | Department of Econometrics and Business Statistics,
      | Monash University
    affiliation: Monash University
    email: dicook@monash.edu
  - name: Earo Wang
    address: |
      | Department of Statistics,
      | The University of Auckland
    affiliation: The University of Auckland
    email: earo.wang@auckland.ac.nz
  - name: H. Sherry Zhang
    address: |
      | Department of Econometrics and Business Statistics,
      | Monash University
    affiliation: Monash University
    email: huize.zhang@monash.edu
title:
  formatted: "An Overview of Tours for Dynamic Visualisation of High-dimensional Data"
abstract: > 
  Abstract goes here.
keywords:
  formatted: ["tours", "data visualisation", "high-dimensional data", "data science", "exploratory data analysis"]
output: 
  bookdown::pdf_document2:
    template: template/wires_template_rmd.tex
    keep_tex: true
    toc: false
bibliography: references.bib
biblio-style: apalike
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  fig.show = 'hold',
  dpi = 300 #,
  # out.width = "\\textwidth",
  # fig.path = here::here('img/')
)
```

<!--
Writing style: third person (it was done, ...)
-->

# Introduction

<!-- Purpose/why and what is high-d data (Di)-->

Data commonly arrives with more than two measured variables, which makes it more complicated to plot on a page. With multiple variables, especially if there is some association between variables, this would be called multivariate or high-dimensional data. When the variables are all numeric, or quantitative, visualisation often relies on some form of dimension reduction. This can be done by taking linear projections, for example, principal component analysis [@Hotelling1933-of] or linear discriminant analysis [@Fisher1936]. It is also common to reduce dimension nonlinearly with techniques like multidimensional scaling (MDS) [@Kruskal1964-do] or t-Distributed Stochastic Neighbour Embedding (t-SNE) [@Van_der_Maaten2008-qa]. 

> Maybe we should clarify What is high-dimensional data? here

The focus of this review will be on linear projections, in particular, as provided by the grand tour [@Asimov1985-xr; @Buja2005-cx]. The reason being that it is not feasible to adequately the very large area of visualising high-dimensions, and there have been numerous developments in tours recently.  An overview of the technique, and new modifications is provided, along with how these techniques can be used in a variety of applications, and to help understand nonlinear dimension reduction results.  

A tour can be considered to be a dynamic graphic, because it shows a smooth sequence of projections over time, ideally with controls that allow stopping, reversing, changing direction, or going forward again. It can be useful to embed a tour into an interactive graphics system, where plots can be queried and elements highlighted (see for e.g. @Swayne2003-cc or @Tierney1991). To create the smooth sequence, a geodesic interpolation is computed between consecutive frames.  It allows the viewer to extrapolate from the low-dimensional to  shapes corresponding to multivariate distribution, and is particularly useful for detecting clusters, outliers and non-linear dependence. 

Nonlinear dimension reduction techniques such as t-SNE have become very popular in recent years, primarily for the ability to capture cluster structure in a succinct visual summary. However, it is only a summary, and it likely involves substantial warping of the original data space. Using the tour along with these techniques can illuminate the nature of the warped space, and reveal other structure lost in the dimension reduction.  Figure \ref{fig:tsne-tour} illustrates the difference in what can be learned from a tour in comparison with nonlinear dimension reduction using t-SNE. The 10-dimensional data comes from @Rauber2009-kk. The t-SNE view (plot A) shows six clearly separated clusters, all spherical with different sizes. The tour shows that the clusters look very little like this in the full data space. The clusters are at various distances apart and very different sizes. In the four projections from the tour this can be seen. The two green clusters are large and spherical, and far from the brown clusters. The brown clusters have one larger one, and three smaller, very close to each other. All of these are elliptical, which means that they have very little variability, actually no variability if you watch the full tour, in some of the 10 dimensions. This gives some deeper perspective to what is learned from t-SNE, and illustrates what the t-SNE dimension reduction has done: it has found small gaps between points and expanded these gaps to yield the representation. It should be noted, though, that the t-SNE view clearly reveals the presence of six distinct clusters. With this information is the invitation to look closer at the data in the tour, to see, that yes, indeed, there are three, tiny, tiny clusters very close to each other.

\begin{figure*}[!t]
         \includegraphics[width=0.5\textwidth]{figures/cluster_example_r.pdf}
     \vfill
   \begin{minipage}{\linewidth}     
   \centering
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour1_r.pdf}
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour2_r.pdf}
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour3_r.pdf}
         \includegraphics[width=0.24\textwidth]{figures/cluster_example_tour4_r.pdf}
   \end{minipage}%
\caption{Comparison of structure perception between nonlinear dimension reduction using t-SNE (A) and projections seen during a tour (B.1-4). There are six clusters, as seen in the t-SNE view, but the relative distance between the clusters is extremely varied. This can be seen in the tour projections. The two green clusters are spherical in shape, and very distance from the brown clusters. Three of the brown clusters are very close to each other (just visible in B.1), and all brown clusters are elliptical. The tour provides a more accurate rendering of the clusters in the high-dimensional space, and complements what is learned from the dimension reduction.}
\label{fig:tsne-tour}
\end{figure*}

While tours are invaluable for assessing the geometry of data, they are by no means the only technique available for visualising structure in high dimensional data. An early technique proposed for assessing pairwise relationships between variables is the scatter plot matrix (SPLOM) [@Tukey1983-fj] <!-- there might be others here(?) -->. In this graphic, the canvas is split into a matrix where each off-diagonal element is a scatter plot of variable pairs, while the diagonal elements are either left blank or represent univariate structure. The SPLOM allows the viewer to assess correlation structure but does not scale to large numbers of variables. 

Similarly, parallel coordinates plots (PCP) can be used to explore correlation and co-linearities in multivariate data [@Inselberg1985-kf]. In PCPs, variables are arranged along the (vertical) horizontal axis with vertical (horizontal) axes drawn representing the range of values for each variable. Points (observations) of the data are represented by drawing lines between each variables axis. If there is positive correlation between two variables the lines will be parallel, while for negative correlation the lines will cross. By placing multiple variables side by side in a PCP higher order structure like clustering or lower dimensional embeddings is revealed, however the ordering of variables is important to reveal these features. <!-- anything else? Andrew's curves etc., heat? -->

<!-- Original tours (Di)
- Dataviewer, XGobi, GGobi, cranvas (XLispStat, Orca, mmvz) (Di)
(picture of the cluster data from Stuart's thesis)
- Alternatives (Stuart) 
  - cluster heatmaps 
  - data pipelines (?)
  - point to other reviews
- What do we mean by multivariate data visualisation?
- multivariate categorical vis, tree maps etc.
- subplots trellis literature
-->


# Tours for high dimensional visualization 

- Bases notation (Sherry)

Some notations are defined for describing $d$-dimensional projections in $p$-dimensional space. Let $X_{n \times p}$ be the original data whose projections are of our interest. A projection basis, $A_{p \times d}$, characterises the direction from which the high-dimensional data are projected. A constraint that projection bases needs to satisfy is the orthonormality condition (which requires each axis to be unit vector and perpendicular to each other). This gives the basis space a geometrical structure of a Stiefel manifold. The projection of the original data on a basis hence can be defined as $Y = X \cdot A$. The projection is usually in 1D or 2D for the purpose of visual display. 

> figure 2 diagram illustrating a projection: Di thinks making a Huber plot (2D data - 1D projection) here with projected data on a couple of directions is ideal

- Display (Sherry)

[@Wickham2011-uz]

1D: `display_hist`: histogram
2D: `display_xy`, recent development `display_sage()` - will be detailed in the last section Transformations on projections (Ursula)

[grand/ guided / manual tour or 1D/ 2D display in tourr???]

grand tour, random, may miss interesting, take long to rotate to that specific angle, guided tour, along with projection pursuit, by generating target bases, interestingness

> figure 3 diagram illustrating different displays for different d



- Choosing targets, inc pp indexes (Sherry)

To define whether a projection is interesting or not in the guided tour, an index function is used. An index function defines a surjection function from the projection $Y$ in $\mathbb{R}^{n \times d}$ to a scalar in $\mathbb{R}$. For the high-dimensional data, an interesting projection is the one that deviates from normality, as discussed in @Diaconis1984-mv and @Huber1985-zq [expand more here]. Numerous index functions have been developed since the initial index proposed by @Friedman1974-ck: <!-- entropy-based index? --> holes and central mass index [@Cook2008-nl] computes the deviation of the projected data from a normal distribution; @Posse1995-ih proposed a chi-square index for detecting the spiral structure in the data;  kurtosis and skewness indices are raised in @Loperfido2020-xj and @Loperfido2018-ga to detect outliers in financial time series; and most recently, scagnostic indices [@Laa2020-zj] provides eight measures for summarising information between pairs of variables in scatter plot matrices. 

> figure 4 diagram illustrating different types of target generation

- Geodesic interpolation (Ursula)

Interpolation is either between frames, or between planes
Interpolation between planes is preferred to avoid distracting effects (rotation in the plane), exception would be projection pursuit indexes that are sensitive to rotation (but that should be avoided when possible)
Geodesic interpolation uses SVD to interpolate along the shortest path between planes

XXX need to decide how much math to put in, if/which picture to use (probably something from @Buja2005-cx)

> figure 5 diagram illustrating geodesic interpolation

- Slices vs projections (Ursula)

Projections can hide certain features, sections can provide additional information @Furnas1994-dz
Sectioning a high-dimensional space in systematic manner is challenging, there are a lot of choices we need to make
Typical approach is interactive: brushing to select sections in one view, highlight points in a second view, e.g. a tour display
Slice tour approach: use distance from the projection plane (through a selected center point), update the section systematically with the projection plane @Laa2020-js
Summary of applications: viewing geometric shapes, model visualization
Connection with projection pursuit: section pursuit @Laa2020-ni

XXX figure should probably be combination of Fig 1 and 2 in @Laa2020-js

> figure 6 diagram illustrating projection vs slice

- Transformations on projections (Ursula)

Transformations of the data are common in the preprocessing, but sometimes we want to transform the data after projecting onto lower dimensions
Example would be to address piling effects that are a result of projecting form high-dimensional space down to low-dimensions
A solution to this problem was presented in the sage display @Laa2020-uv and is using a radial transformation of the projected data to avoid piling near the center
Summary of applications: better understanding of clustering in high-dimensional space (discussed below), resolving small features near the center

XXX I would like Fig 5 of @Laa2020-uv as an illustration here

> figure 7 diagram of burning sage transformation

# Ways of interacting

- Stop/start/reverse

> pull something from ggobi book?
> figure 8 illustration

## Manual tour (Nick)

Manual tours [@cook_manual_1997; @spyrison_spinifex_2020] offer a means to interactively control the contribution of a single variable on the projection plane. This is particularly useful for exploring a projection once a feature of interest has been identified. Manual tours can then be employed to explore local area of, or test the structure of the feature, with respect to a selected variable.

The details of performing a manual tour are described by @spyrison_spinifex_2020, but high-level unit-interaction between each frame is as follows:

__Input:__ Starting basis, manipulation variable, an in-plane rotation angle -- $\theta$, an out-of-plane rotation angle -- $\phi$  $\\$
__Output:__ Rotated basis $\\$
__Steps:__

1. Initialise a manipulation dimension onto the start basis. Given the manipulation variable a full contribution and orthonormalise this space. 
2. Post-multiply the space, by a rotation matrix, as solved for in application of Rodrigues’ formula [@rodrigues_lois_1840].
3. Truncate the manipulation dimension.

Figure \ref{fig:manual-tour} illustrates the manual tour, by radially manipulating the contribution of variable that is crucial, to explain the separation of a particular cluster. To start we first identify a basis by orthonormalising the linear discriminant. We select a variable that has a large contribution in the basis, and watch a continuous animation as this variable is rotated fully into the projection, compeletely out of the projection, and then returned to it's original contribution.

```{r manual-tour, out.width="100%", fig.show='asis', fig.cap='Manual tour of flea data. We initalise the start basis to the linear discriminant analysis and select the variable with the largest contribution separating the cluster shown as green circles. By controlling the contribution of the variable we see that it is quite sensitive to the sepration of this cluster.', eval=FALSE}
if(F) ## Creation and saving figure at:
  file.edit("./R/make_radial_tour_fig.r")
knitr::include_graphics("./figures/fig_radial_manual_tour.png")
```


\begin{figure*}[!h]
   \centering
         \includegraphics[width=0.32\textwidth]{figures/penguins_manual_bl1_r.pdf}
         \includegraphics[width=0.32\textwidth]{figures/penguins_manual_bl3_r.pdf}
         \includegraphics[width=0.32\textwidth]{figures/penguins_manual_bl4_r.pdf}
\caption{Four projections from a manual tour where variable "bl" is being rotated out of the projection (orange line). When this variable is removed the two light green clusters merge, which informs us that "bl" is an important variable for distinguishing between these two groups.}
\label{fig:manual-tour}
\end{figure*}


- Linked brushing (Earo)

> something from ggobi book
* Brushing as database query
* Brushing as conditioning
* Brushing as geometric sectioning
* Persistent vs. transient 
> > figure 10: plots showing example

- Spin-and-brush  (Ursula)

Tour for visual cluster analysis, identification of outlying points
Maybe the physics example from the ggobi book: find group in one view, highlight, restart tour, and so on, in the end we can review the tour with groups highlighted in colour to get an overview of how the data clusters
Requires persistent brushing with multiple groups
    
> something from ggobi book
> figure 11: plots showing example

# Software

- tourr (Di) 
- spinifex (Nick)

The R package spinifex [@spyrison_spinifex_2020] has 3 primary features: it produces manual tours (predefined path or interactive manipulation, identifies orthonormal global feature bases with the use of the Rdimtools [@you_rdimtools_2020] package, renders (manual or other) tours as animations exportable to static .gif (gganimate [@pedersen_gganimate_2020] package) or interactive .html widgets (plotly [@sievert_interactive_2020] package), lastly it offers interactive shiny application that offers an graphical user interface to quickly sample tour features.

- liminal (Stuart)

The liminal R package uses the tour to explore the quality of non-linear dimensionality reduction algorithms. The interface consists of two side by side views consisting of a scatter plot displaying a reduced form of the data, and an interactive tour. Controls such as play/stop/restart are implemented allowing a user to pause on interesting projections and return them to their R session for further analysis. Linked brushing is implemented on both views - if a users brush on the scatter plot view they can see if and how an algorithm like t-SNE has distorted distances in higher dimensional space, while if they brush on the tour view, the tour is paused and structure like cluster separation can be ascertained.      


- python (Di to follow up with Csaba)

# Application

- Model vis examples eg random forest (from Hadley, removing the blindfold) (Natalia)

> figure 12 tour plot(s) of vote matrix and tour plot(s) of variables, with some annotation of cases?

- Physics (Ursula)

Physics models often consider $\mathcal{O}(10)$ free parameters and are compared to a much larger number of experimental observables ($\mathcal{O}(100)$). The comparison typically relies on numeric computation of the model predictions for all observables, potentially obscuring the nature of their dependence on the model parameters. Here, multivariate visualisation methods can provide new insights. This was demonstrated in @Cook2018-jm. For example, we explored grouping of experiments based on how they constrain the parameter space and we also identified an interesting multivariate outlier that pointed to potential issues with the data point. For illustration we show static views from the tour showing the orthogonal structure of the three groups (indicated by color), and a display which highlights the outlyingness of the data point marked with an asterix symbol.

XXX need to select plots, also based on how much space we want to use

> figure 13 

- Bioinformatics (Stuart)

In single cell RNA sequencing, scientists are interested in identifying novel cell types and understanding the relationships between cells or their developmental trajectory. To achieve this they perform cluster analysis on a counts matrix or principal components and embed the results via t-SNE and label points according the cluster label. One of the main advantages of t-SNE is the avoidance of over-plotting so clusters can be clearly identified on a scatter plot, however, this can come at the cost of interpretability as global distances are distorted.  In @Laa2020-uv, we used radial transformations of the tour projections as an alternative to t-SNE that better preserves global structure while still retaining cluster topology.

> figure 14

- High-d shapes/distributions: normal, skewed, outliers, (Di from tutorial notes)

> figure 15

- neural networks (from Scheidegger - Stuart)

The grand tour along with direct interaction techniques has been proposed as a technique for understanding the training of deep neural network models [@Li2020-kg]. They proposed a novel method for aligning the output of different layers by interpolating the output of different layers of a deep neural network via the the grand tour. They also apply the grand tour to explore the changes in single layers of the network for each training epoch. For example, by the running tour over the softmax layer outputs of a classification model, an analyst may understand where in the training confusion between classes occur and gain a view of model performance. Similarly, the difference between training and test sets can be assessed through side by side linked tours of layer outputs. @li_toward_2020 extends this idea by first reducing the dimensionality of output layers with UMAP and then using the grand tour with manual controls over 15 dimensional embeddings to understand layer topology.

> figure 16 panel a and b


# Discussion

# References {-}
